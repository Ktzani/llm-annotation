# ğŸ¤— Guia de Uso com Datasets do HuggingFace

Este guia mostra como integrar seus datasets do HuggingFace (waashk) com o sistema de anotaÃ§Ã£o.

---

## ğŸš€ InÃ­cio RÃ¡pido (3 Passos)

### 1. Instalar DependÃªncias

```bash
poetry install
```

### 2. Descobrir Estrutura dos Seus Datasets

```bash
python src/main_huggingface.py --modo descobrir --dataset waashk/seu-dataset
```

Isso mostra:
- âœ… Colunas disponÃ­veis
- âœ… Features
- âœ… Exemplos
- âœ… SugestÃ£o de configuraÃ§Ã£o

### 3. Configurar e Executar

Edite `src/config/dataset_config.py` e adicione seu dataset:

```python
HUGGINGFACE_DATASETS = {
    "meu_dataset": {
        "path": "waashk/nome-do-dataset",
        "text_column": "text",
        "label_column": "label",  # ou None
        "categories": ["Cat1", "Cat2"],
        "split": "train",
        "sample_size": 100,  # ComeÃ§ar pequeno!
    },
}
```

Execute:

```bash
python src/main_huggingface.py --modo basico
```

---

## ğŸ“‹ ConfiguraÃ§Ã£o Detalhada

### Estrutura de ConfiguraÃ§Ã£o

```python
"nome_dataset": {
    # OBRIGATÃ“RIOS
    "path": str,           # Path no HuggingFace
    "text_column": str,    # Coluna com textos
    "split": str,          # "train", "test", etc
    
    # OPCIONAIS
    "label_column": str,   # Coluna com labels (para validaÃ§Ã£o)
    "categories": list,    # ou None (extrair automaticamente)
    "sample_size": int,    # ou None (carregar tudo)
    "description": str,    # DescriÃ§Ã£o do dataset
    
    # AVANÃ‡ADO: Combinar mÃºltiplos splits
    "combine_splits": ["train", "test"],  # Usar dataset completo
}
```

### Exemplo Real

```python
"sentiment_reviews": {
    "path": "waashk/sentiment-reviews",
    "text_column": "review_text",
    "label_column": "sentiment",
    "categories": None,  # Extrair automaticamente
    "split": "train",
    "sample_size": 500,
    "description": "Reviews de produtos para anÃ¡lise de sentimento"
}
```

---

## ğŸ¯ Casos de Uso

### Caso 1: Dataset com Labels (ValidaÃ§Ã£o)

VocÃª tem labels para validar a qualidade:

```python
"dataset_validacao": {
    "path": "waashk/dataset-com-labels",
    "text_column": "text",
    "label_column": "label",  # â† Importante!
    "categories": None,  # Extrair das labels
    "split": "train",
    "sample_size": None,
}
```

O sistema automaticamente:
- âœ… Extrai categorias dos labels
- âœ… Calcula accuracy vs ground truth
- âœ… Gera relatÃ³rio de validaÃ§Ã£o

### Caso 2: Dataset sem Labels (AnotaÃ§Ã£o Pura)

VocÃª quer anotar do zero:

```python
"dataset_anotacao": {
    "path": "waashk/textos-nao-rotulados",
    "text_column": "content",
    "label_column": None,  # â† Sem labels
    "categories": ["Spam", "Ham", "Unsure"],  # â† VocÃª define
    "split": "train",
    "sample_size": None,
}
```

### Caso 3: Dataset Completo (Todos os Splits)

Usar dataset inteiro para anotaÃ§Ã£o:

```python
"dataset_completo": {
    "path": "waashk/meu-dataset",
    "text_column": "text",
    "label_column": None,
    "categories": ["A", "B", "C"],
    "combine_splits": ["train", "test", "validation"],  # â† Combinar!
    "sample_size": None,
}
```

### Caso 4: Amostra Pequena (Teste)

ComeÃ§ar com amostra para testar:

```python
"dataset_teste": {
    "path": "waashk/dataset-grande",
    "text_column": "text",
    "label_column": "category",
    "categories": None,
    "split": "train",
    "sample_size": 50,  # â† Apenas 50 para teste!
}
```

---

## ğŸ’» Exemplos de CÃ³digo

### Exemplo 1: BÃ¡sico

```python
from dataset_config import load_hf_dataset
from llm_annotator import LLMAnnotator

# Carregar dataset
texts, categories, ground_truth = load_hf_dataset("meu_dataset")

# Configurar
api_keys = {...}
models = ["gpt-4-turbo", "claude-3-opus", "gemini-pro"]

# Anotar
annotator = LLMAnnotator(models, categories, api_keys)
df = annotator.annotate_dataset(texts, num_repetitions=3)
df = annotator.calculate_consensus(df)

# Validar (se houver ground truth)
if ground_truth:
    df['ground_truth'] = ground_truth
    from sklearn.metrics import accuracy_score
    acc = accuracy_score(df['ground_truth'], df['most_common_annotation'])
    print(f"Accuracy: {acc:.2%}")
```

### Exemplo 2: Dataset Customizado

```python
from dataset_config import load_custom_dataset

# Carregar sem prÃ©-configurar
texts, categories, labels = load_custom_dataset(
    hf_path="waashk/dataset-qualquer",
    text_column="minha_coluna",
    label_column=None,
    categories=["X", "Y", "Z"],
    combine_splits=["train", "test"],  # Dataset completo
    sample_size=100
)
```

### Exemplo 3: Como DataFrame

```python
from dataset_config import load_hf_dataset_as_dataframe

# Carregar como pandas DataFrame
df = load_hf_dataset_as_dataframe("meu_dataset")

# AnÃ¡lise exploratÃ³ria
print(df.head())
print(df['ground_truth'].value_counts())

# Usar com anotador
texts = df['text'].tolist()
```

---

## ğŸ” Descobrir Estrutura

NÃ£o sabe a estrutura do seu dataset?

### MÃ©todo 1: Via Script

```bash
python src/main_huggingface.py --modo descobrir --dataset waashk/seu-dataset
```

### MÃ©todo 2: Via CÃ³digo

```python
from dataset_config import discover_dataset_structure

discover_dataset_structure("waashk/seu-dataset", num_examples=5)
```

Isso mostra:
```
ğŸ“‹ Estrutura do dataset:
   Colunas: ['text', 'label', 'id']
   Features: {'text': Value(dtype='string'), 'label': ClassLabel(...)}

ğŸ“ Primeiros 3 exemplos:
   Exemplo 1:
      text: Este Ã© um texto exemplo...
      label: positivo
      id: 1
```

---

## ğŸƒ Executar

### Modo BÃ¡sico

```bash
python src/main_huggingface.py --modo basico
```

Executa fluxo completo:
1. Carrega dataset configurado
2. Anota com mÃºltiplas LLMs
3. Calcula consenso
4. Valida com ground truth (se disponÃ­vel)
5. Gera visualizaÃ§Ãµes
6. Salva resultados

### Modo Descobrir

```bash
python src/main_huggingface.py --modo descobrir --dataset waashk/seu-dataset
```

Descobre estrutura do dataset.

### Modo Customizado

```bash
python src/main_huggingface.py --modo customizado
```

Exemplo de carregamento sem prÃ©-configurar.

### Modo MÃºltiplos

```bash
python src/main_huggingface.py --modo multiplos
```

Processa vÃ¡rios datasets em batch.

---

## ğŸ“ Estrutura de Arquivos

```
src/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ dataset_config.py       â­ ConfiguraÃ§Ã£o de datasets
â”œâ”€â”€ llm_annotation_system/
â”‚   â”œâ”€â”€ llm_annotator.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ main.py                     Original (exemplo simples)
â””â”€â”€ main_huggingface.py         â­ Novo (com HuggingFace)

data/
â””â”€â”€ .cache/
    â””â”€â”€ huggingface/            Cache local dos datasets

results/
â”œâ”€â”€ dataset_anotado_final.csv   â­ Dataset anotado
â”œâ”€â”€ figures/
â””â”€â”€ ...
```

---

## ğŸ› Troubleshooting

### Erro: "Column not found"

```python
# Verificar colunas disponÃ­veis
python src/main_huggingface.py --modo descobrir --dataset waashk/seu-dataset

# Ajustar config
"text_column": "nome_correto_da_coluna"
```

### Erro: "Dataset not found"

```bash
# Verificar se dataset existe
# Ir em: https://huggingface.co/waashk

# Se for privado, fazer login
huggingface-cli login
```

### Dataset muito grande

```python
# Usar amostragem
"sample_size": 1000  # Apenas 1000 exemplos

# Ou processar em batches
for i in range(0, total, 1000):
    texts = load_dataset(...).select(range(i, i+1000))
```

### Combinar splits nÃ£o funciona

```python
# Verificar splits disponÃ­veis primeiro
discover_dataset_structure("waashk/seu-dataset")

# Ajustar lista
"combine_splits": ["train", "test"]  # Apenas os que existem
```

---

## ğŸ’¡ Dicas

### 1. Sempre ComeÃ§ar Pequeno

```python
"sample_size": 100  # â† ComeÃ§ar com 100 textos
```

Validar que funciona, depois aumentar!

### 2. Cache Local

Datasets sÃ£o salvos em cache:

```bash
# Ver cache
ls -lh data/.cache/huggingface/

# Limpar se necessÃ¡rio
rm -rf data/.cache/huggingface/
```

### 3. ValidaÃ§Ã£o com Ground Truth

Se seu dataset tem labels:

```python
# Sistema automaticamente:
# 1. Calcula accuracy
# 2. Gera classification report
# 3. Identifica categorias problemÃ¡ticas
```

### 4. Processar em Batches

Para datasets grandes:

```python
# Dividir em partes
batch_size = 500
for i in range(0, len(texts), batch_size):
    batch = texts[i:i+batch_size]
    # Processar batch...
```

---

## âœ… Checklist

Antes de comeÃ§ar:

- [ ] `poetry install` executado
- [ ] Datasets identificados em https://huggingface.co/waashk
- [ ] Estrutura descoberta com `--modo descobrir`
- [ ] ConfiguraÃ§Ã£o adicionada em `dataset_config.py`
- [ ] Testado com amostra pequena (`sample_size: 100`)
- [ ] API keys configuradas no `.env`
- [ ] Pronto para anotaÃ§Ã£o completa! ğŸš€

---

## ğŸ“Š Fluxo Completo

```
1. DESCOBRIR           â†’ python ... --modo descobrir
   â†“
2. CONFIGURAR          â†’ Editar dataset_config.py
   â†“
3. TESTAR (amostra)    â†’ sample_size: 100
   â†“
4. VALIDAR             â†’ Verificar resultados
   â†“
5. ESCALAR             â†’ sample_size: None (tudo)
   â†“
6. ANALISAR            â†’ Ver dashboard e mÃ©tricas
```

---

## ğŸ“ Recursos

- **HuggingFace Datasets**: https://huggingface.co/docs/datasets/
- **Seus datasets**: https://huggingface.co/waashk
- **DocumentaÃ§Ã£o do projeto**: README.md

---

**Boa sorte com suas anotaÃ§Ãµes!** ğŸ¤—ğŸš€
