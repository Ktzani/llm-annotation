# Sistema de AnotaÃ§Ã£o AutomÃ¡tica com MÃºltiplas LLMs

Sistema completo para reduzir custos humanos na anotaÃ§Ã£o de datasets atravÃ©s do uso de mÃºltiplas LLMs e anÃ¡lise de consenso.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Metodologia](#metodologia)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Guia Detalhado](#guia-detalhado)
- [Resultados e MÃ©tricas](#resultados-e-mÃ©tricas)
- [FAQ](#faq)

## ğŸ¯ VisÃ£o Geral

Este projeto implementa uma metodologia para anotaÃ§Ã£o automÃ¡tica de datasets usando mÃºltiplas LLMs (Large Language Models) com anÃ¡lise de consenso. O objetivo Ã© reduzir significativamente o custo e tempo necessÃ¡rios para anotaÃ§Ã£o manual, mantendo alta qualidade nas classificaÃ§Ãµes.

### CaracterÃ­sticas Principais

âœ… **MÃºltiplas LLMs**: Suporte para GPT-4, GPT-3.5, Claude 3, Gemini, e Cohere  
âœ… **Consenso Robusto**: Cada LLM anota mÃºltiplas vezes para validaÃ§Ã£o interna  
âœ… **AnÃ¡lise EstatÃ­stica**: MÃ©tricas completas de concordÃ¢ncia (Cohen's Kappa, Fleiss' Kappa, etc.)  
âœ… **VisualizaÃ§Ãµes**: GrÃ¡ficos e dashboards interativos  
âœ… **HuggingFace**: IntegraÃ§Ã£o completa com datasets do HuggingFace  
âœ… **FlexÃ­vel**: Suporte para diferentes estratÃ©gias de resoluÃ§Ã£o de conflitos  
âœ… **Cache**: Sistema de cache para economizar chamadas de API  

## ğŸ“Š Metodologia

A metodologia implementada segue os seguintes passos:

### 1. AnotaÃ§Ã£o MÃºltipla
- 5 LLMs diferentes anotam cada instÃ¢ncia do dataset
- Cada LLM faz mÃºltiplas anotaÃ§Ãµes (padrÃ£o: 3x) da mesma instÃ¢ncia
- ValidaÃ§Ã£o de consenso interno para cada LLM

### 2. AnÃ¡lise de Consenso
- CÃ¡lculo de tabela de consenso entre LLMs
- EstatÃ­sticas por instÃ¢ncia (porcentagem de acordo)
- IdentificaÃ§Ã£o de casos problemÃ¡ticos (empates, discordÃ¢ncias)

### 3. ValidaÃ§Ã£o de ParÃ¢metros (LLM Hacking)
- Teste de diferentes configuraÃ§Ãµes (temperatura, top_p, etc.)
- AvaliaÃ§Ã£o do impacto de variaÃ§Ãµes de parÃ¢metros
- IdentificaÃ§Ã£o de configuraÃ§Ãµes mais estÃ¡veis

### 4. EstratÃ©gias de ResoluÃ§Ã£o
Para casos sem consenso claro:
- **Voto majoritÃ¡rio**: Escolhe a classe mais votada
- **Threshold**: Aceita apenas se consenso â‰¥ X%
- **Flag for review**: Marca para revisÃ£o humana
- **Remove**: Remove instÃ¢ncias problemÃ¡ticas
- **Weighted vote**: Voto ponderado por confiabilidade do modelo

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.9+
- Poetry (gerenciador de dependÃªncias)
- API keys para as LLMs que deseja usar

### InstalaÃ§Ã£o de DependÃªncias

```bash
# Instalar dependÃªncias com Poetry
poetry install
```

### Configurar API Keys

Crie um arquivo `.env` na raiz do projeto:

```env
OPENAI_API_KEY=sua-chave-aqui
ANTHROPIC_API_KEY=sua-chave-aqui
GOOGLE_API_KEY=sua-chave-aqui
```

## ğŸƒ Uso RÃ¡pido

### OpÃ§Ã£o 1: Notebook Jupyter (RECOMENDADO)

```bash
poetry run jupyter notebook src/notebooks/analise_consenso_llms.ipynb
```

Este notebook contÃ©m:
- Setup completo
- Exemplos de uso
- AnÃ¡lises detalhadas
- VisualizaÃ§Ãµes
- InterpretaÃ§Ã£o de resultados

### OpÃ§Ã£o 2: Script Principal

```bash
# Exemplo bÃ¡sico
poetry run python src/main.py

# Com datasets HuggingFace
poetry run python src/main_huggingface.py --modo basico
```

## ğŸ¤— Datasets do HuggingFace

Este projeto tem suporte completo para datasets do HuggingFace!

### InÃ­cio RÃ¡pido com HuggingFace

1. **Descobrir estrutura do dataset:**
```bash
poetry run python src/main_huggingface.py --modo descobrir --dataset waashk/seu-dataset
```

2. **Configurar dataset:**
Edite `src/config/dataset_config.py` com as informaÃ§Ãµes do seu dataset

3. **Executar anotaÃ§Ã£o:**
```bash
poetry run python src/main_huggingface.py --modo basico
```

### DocumentaÃ§Ã£o HuggingFace

Ver guias completos:
- [GUIA_DATASETS.md](docs/GUIA_DATASETS.md) - Guia completo

### Arquivos Importantes

- `src/config/dataset_config.py` - ConfiguraÃ§Ã£o de datasets HuggingFace
- `src/main_huggingface.py` - Script principal com HuggingFace
- `docs/GUIA_DATASETS.md` - Guia completo de uso

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ pyproject.toml                    # ConfiguraÃ§Ã£o Poetry
â”œâ”€â”€ .env                              # API keys (criar)
â”œâ”€â”€ Makefile                          # Comandos Ãºteis
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/                       # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ prompts.py               # Templates de prompts
â”‚   â”‚   â”œâ”€â”€ llm_configs.py           # ConfiguraÃ§Ã£o de modelos
â”‚   â”‚   â”œâ”€â”€ experiment.py            # ParÃ¢metros do experimento
â”‚   â”‚   â”œâ”€â”€ evaluation.py            # MÃ©tricas de avaliaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ conflict_resolution.py   # EstratÃ©gias de resoluÃ§Ã£o
â”‚   â”‚   â””â”€â”€ dataset_config.py        # â­ Datasets HuggingFace
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_annotation_system/        # CÃ³digo principal
â”‚   â”‚   â”œâ”€â”€ llm_annotator.py         # Anotador principal
â”‚   â”‚   â”œâ”€â”€ consensus_analyzer.py    # AnÃ¡lise de consenso
â”‚   â”‚   â””â”€â”€ visualizer.py            # VisualizaÃ§Ãµes
â”‚   â”‚
â”‚   â”œâ”€â”€ notebooks/                    # Jupyter Notebooks
â”‚   â”‚   â””â”€â”€ analise_consenso_llms.ipynb  # â­ Notebook principal
â”‚   â”‚
â”‚   â”œâ”€â”€ main.py                       # Script exemplo bÃ¡sico
â”‚   â””â”€â”€ main_huggingface.py           # â­ Script com HuggingFace
â”‚
â”œâ”€â”€ data/                             # Dados
â”‚   â””â”€â”€ .cache/                       # Cache de datasets
â”‚
â”œâ”€â”€ results/                          # Resultados gerados
â”‚   â”œâ”€â”€ figures/                      # VisualizaÃ§Ãµes
â”‚   â”œâ”€â”€ reports/                      # RelatÃ³rios CSV
â”‚   â””â”€â”€ final/                        # Resultados finais
â”‚
â””â”€â”€ docs/                             # DocumentaÃ§Ã£o
    â”œâ”€â”€ INSTRUCOES.md
    â”œâ”€â”€ RESUMO_EXECUTIVO.md
    â””â”€â”€ GUIA_DATASETS.md          # â­ Guia HuggingFace
    
```

## ğŸ“– Guia Detalhado

### Customizar Prompts

Edite `src/config/prompts.py`:

```python
BASE_ANNOTATION_PROMPT = """You are an expert...
{text}
{categories}
"""
```

### Adicionar Novos Modelos

Em `src/config/llm_configs.py`:

```python
LLM_CONFIGS["seu-modelo"] = {
    "provider": "openai",
    "model_name": "nome-do-modelo",
    "default_params": {"temperature": 0.0}
}
```

### Configurar Datasets HuggingFace

Em `src/config/dataset_config.py`:

```python
HUGGINGFACE_DATASETS = {
    "meu_dataset": {
        "path": "waashk/nome-dataset",
        "text_column": "text",
        "label_column": "label",  # opcional
        "categories": None,  # extrair automaticamente
        "combine_splits": ["train", "test"],  # dataset completo
        "sample_size": 100,  # comeÃ§ar pequeno
    }
}
```

### Testar VariaÃ§Ãµes de ParÃ¢metros

```python
df = annotator.annotate_dataset(
    texts=texts,
    test_param_variations=True  # Testa diferentes parÃ¢metros
)
```

## ğŸ“Š Resultados e MÃ©tricas

### InterpretaÃ§Ã£o

**Cohen's Kappa**:
- `> 0.80`: Excelente âœ…
- `0.60 - 0.80`: Bom âœ…
- `0.40 - 0.60`: Moderado âš ï¸
- `< 0.40`: Fraco âŒ

**Consenso Score**:
- `â‰¥ 80%`: Alto - aceitar âœ…
- `60-80%`: MÃ©dio - revisar amostra âš ï¸
- `< 60%`: Baixo - revisÃ£o obrigatÃ³ria âŒ

### Arquivos Gerados

1. **dataset_anotado_final.csv**: Dataset com anotaÃ§Ãµes finais
2. **annotations_complete.csv**: Todas anotaÃ§Ãµes detalhadas
3. **high_confidence_annotations.csv**: Consenso â‰¥ 80%
4. **needs_human_review.csv**: Casos problemÃ¡ticos
5. **experiment_summary.json**: EstatÃ­sticas completas
6. **interactive_dashboard.html**: Dashboard interativo

## ğŸ”§ Comandos Make

```bash
make help              # Ver todos os comandos
make install           # Instalar dependÃªncias
make notebook          # Abrir Jupyter Notebook
make clean             # Limpar arquivos temporÃ¡rios
make format            # Formatar cÃ³digo
make lint              # Verificar cÃ³digo
```

## ğŸ’¡ FAQ

**Q: Quantos modelos usar?**  
A: Recomendamos 5 modelos de diferentes provedores para consenso robusto.

**Q: Quantas repetiÃ§Ãµes?**  
A: 3 repetiÃ§Ãµes Ã© um bom balanÃ§o entre confiabilidade e custo.

**Q: Como reduzir custos?**  
A: Use cache, amostras pequenas (`sample_size`), e modelos mais baratos inicialmente.

**Q: O que fazer com casos sem consenso?**  
A: Depende do caso - revisÃ£o humana Ã© mais confiÃ¡vel, voto majoritÃ¡rio Ã© mais rÃ¡pido.

**Q: Como usar meus datasets do HuggingFace?**  
A: Veja [GUIA_HUGGINGFACE.md](docs/GUIA_HUGGINGFACE.md) para instruÃ§Ãµes completas.

**Q: Posso usar o dataset completo sem dividir train/test?**  
A: Sim! Use `combine_splits: ["train", "test"]` em `dataset_config.py`.

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [INSTRUCOES.md](docs/INSTRUCOES.md) - Guia rÃ¡pido geral
- [RESUMO_EXECUTIVO.md](docs/RESUMO_EXECUTIVO.md) - Resumo para orientador
- [GUIA_DATASETS.md](docs/GUIA_DATASETS.md) - Guia completo HuggingFace

---
