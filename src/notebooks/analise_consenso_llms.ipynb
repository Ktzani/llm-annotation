{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ An√°lise de Consenso entre LLMs\n",
    "## Notebook Refatorado com Alternative Params\n",
    "\n",
    "Este notebook usa:\n",
    "- Componentes modulares\n",
    "- Logging com loguru\n",
    "- Integra√ß√£o com HuggingFace\n",
    "- **Alternative params** para testar varia√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:09\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m‚úì Setup completo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import os\n",
    "\n",
    "# Configurar logging\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    format=\"<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>\",\n",
    "    level=\"INFO\"\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Setup completo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Carregar Dataset do HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:09\u001b[0m | \u001b[1mDatasets dispon√≠veis:\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - agnews\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - mpqa\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - webkb\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - ohsumed\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - acm\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - yelp_2013\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - dblp\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - books\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - reut90\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - wos11967\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - twitter\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - trec\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - wos5736\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - sst1\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - pang_movie\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - movie_review\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - vader_movie\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - subj\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - sst2\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - yelp_reviews\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - 20ng\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1m  - medline\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_loader import load_hf_dataset, load_hf_dataset_as_dataframe, list_available_datasets\n",
    "\n",
    "# Listar datasets\n",
    "logger.info(\"Datasets dispon√≠veis:\")\n",
    "for dataset in list_available_datasets():\n",
    "    logger.info(f\"  - {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:09\u001b[0m | \u001b[1mCarregando dataset: agnews\u001b[0m\n",
      "\u001b[32m17:11:09\u001b[0m | \u001b[1mCombinando splits: ['train', 'test']\u001b[0m\n",
      "\u001b[32m17:11:15\u001b[0m | \u001b[1m  ‚úì train: 510400 exemplos\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m  ‚úì test: 127600 exemplos\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mTotal combinado: 638000 exemplos\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mCategorias extra√≠das automaticamente: [0, 1, 2, 3]\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mAmostra reduzida para 100 exemplos\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mColuna de texto: text\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mGround truth carregado da coluna 'label'\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mTextos: 100\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mCategorias: [0, 1, 2, 3]\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mGround truth: Sim\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Carregar dataset\n",
    "dataset_name = \"agnews\"  # Ajuste conforme necess√°rio\n",
    "\n",
    "texts, categories, ground_truth = load_hf_dataset(dataset_name)\n",
    "\n",
    "logger.info(f\"Textos: {len(texts)}\")\n",
    "logger.info(f\"Categorias: {categories}\")\n",
    "logger.info(f\"Ground truth: {'Sim' if ground_truth else 'N√£o'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m\n",
      "Amostra dos textos:\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m1. \"Irish Claim 2nd Title\",\"Notre Dame goalkeeper Erika Bohn seals the Irish's second NCAA championship...\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m   Label: 1\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m2. \"Court rules for BC in flap over exit fee\",\"Boston College cleared a major legal hurdle in its bid t...\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m   Label: 1\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m3. \"Scientific Method Man\",\"Gordon Rugg cracked the 400-year-old mystery of the Voynich manuscript. Nex...\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1m   Label: 3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Visualizar amostra\n",
    "logger.info(\"\\nAmostra dos textos:\")\n",
    "for i, text in enumerate(texts[:3]):\n",
    "    logger.info(f\"{i+1}. {text[:100]}...\")\n",
    "    if ground_truth:\n",
    "        logger.info(f\"   Label: {ground_truth[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mCarregando dataset: agnews\u001b[0m\n",
      "\u001b[32m17:11:20\u001b[0m | \u001b[1mCombinando splits: ['train', 'test']\u001b[0m\n",
      "\u001b[32m17:11:25\u001b[0m | \u001b[1m  ‚úì train: 510400 exemplos\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1m  ‚úì test: 127600 exemplos\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1mTotal combinado: 638000 exemplos\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1mCategorias extra√≠das automaticamente: [0, 1, 2, 3]\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1mAmostra reduzida para 100 exemplos\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1mColuna de texto: text\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1mGround truth carregado da coluna 'label'\u001b[0m\n",
      "\u001b[32m17:11:31\u001b[0m | \u001b[1mDataFrame criado com 100 linhas\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df, categories = load_hf_dataset_as_dataframe(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6ef43137-889b-45ba-8c0f-eaf63c8b80a1",
       "rows": [
        [
         "0",
         "\"Irish Claim 2nd Title\",\"Notre Dame goalkeeper Erika Bohn seals the Irish's second NCAA championship with a save in penalty kicks to lift them to a 4-3 victory over North Carolina on Sunday.\"",
         "1"
        ],
        [
         "1",
         "\"Court rules for BC in flap over exit fee\",\"Boston College cleared a major legal hurdle in its bid to join the Atlantic Coast Conference yesterday when a Massachusetts Superior Court judge issued summary judgment in favor of the school's attempt to depart the Big East next July under the old provisions of the conference's constitution.\"",
         "1"
        ],
        [
         "2",
         "\"Scientific Method Man\",\"Gordon Rugg cracked the 400-year-old mystery of the Voynich manuscript. Next up: everything from Alzheimer's to the origins of the universe. By Joseph D'Agnese from Wired magazine.\"",
         "3"
        ],
        [
         "3",
         "\"Money From Salvadoran Immigrants Aids Farming Cooperative Back Home\",\"SAN PEDRO MASAHUAT, El Salvador -- Marta Sonia Ayala hunched over a metal table in a room that resembles a large restaurant kitchen, scooping heaps of a light brown powder into plastic bags. Later, she placed the bags of &lt;em&gt;frijolito&lt;/em&gt; -- beans ground into flour -- in a heat-sealing machine, placed colored labels on them and shipped them to 22 stores throughout the country where they would sell for \\$1.35 a pound.\"",
         "2"
        ],
        [
         "4",
         "\"U.S. Pounds Falluja Diehards, Violence in North\",\" FALLUJA, Iraq (Reuters) - U.S. artillery pummelled Falluja  on Wednesday and troops hunted guerrillas still fighting days  after Washington said its offensive had destroyed rebel control  of the Sunni Muslim city west of Baghdad.\"",
         "0"
        ],
        [
         "5",
         "\"Roon at the top - hat-trick hero Wayne makes dazzling United debut\",\"WAYNE ROONEY launched himself into the footballing stratosphere with a debut hat-trick at Old Trafford last night. On this evidence, Sir Alex Ferguson would have made a wise investment if he had spent the \"",
         "1"
        ],
        [
         "6",
         "\"Indonesia steps up clamp on militants\",\"JAKARTA: Indonesian police said yesterday they had redoubled efforts to track militants blamed for a suicide car bomb attack on the Australian embassy, and released video recordings of the powerful blast.\"",
         "0"
        ],
        [
         "7",
         "\"Friendly Audience for Hamm\",\"aul Hamm was no longer in Athens last night but instead was on the set of  quot;Late Show With David Letterman quot; carrying his three Olympic medals.\"",
         "1"
        ],
        [
         "8",
         "\"Hurricane Jeanne Continues to Ravage Fla.\",\"MELBOURNE, Fla. - Hurricane Jeanne tore a fresh path of destruction and despair as it continued its march up storm-ravaged Florida, where the fourth major hurricane in six weeks shut down much of the state and prompted recovery plans on a scale never before seen in the nation...\"",
         "0"
        ],
        [
         "9",
         "\"Fed minutes show dissent over inflation (USATODAY.com)\",\"USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.\"",
         "2"
        ],
        [
         "10",
         "\"XM Satellite Radio to Begin Broadcasting on Web\",\"XM Satellite Radio Holdings Inc. (XMSR) will soon begin broadcasting some of its stations to subscribers over the Internet, fresh on the heels of the company's discontinuation of a receiver for PCs that some users used to circumvent the music industry's crackdown on illegal file sharing.\"",
         "3"
        ],
        [
         "11",
         "\"BT And Blueprint Jointly Develop Innovative Music Distribution &lt;b&gt;...&lt;/b&gt;\",\"In yet another move in the legitimate digital music market, BT and Blueprint have jointly developed a new service based on Blueprints Open Royalty Gateway (ORG) and Song Centre software that allows copyright holders to take more control of their \"",
         "3"
        ],
        [
         "12",
         "\"Yahoo! awards world #39;s best cybercafes\",\"London, September 1: A San Francisco laundromat may be the one of the world #39;s most unusual places to surf the Internet but a sleek club on Moscow #39;s Red Square is definitely the sleekest, according to a Yahoo!\"",
         "3"
        ],
        [
         "13",
         "\"Dollar Dips Against Most Major Currencies\",\" NEW YORK (Reuters) - The dollar dipped against most major  currencies on Wednesday after mixed data on U.S. durable goods  orders and weaker-than-expected new home sales did little to  brighten the U.S. economic outlook.\"",
         "2"
        ],
        [
         "14",
         "\"Sunday #39;s NFL Capsules\",\"Philadelphia won a fourth consecutive NFC East title as Brian Westbrook scored two touchdowns Sunday and the Eagles #39; defense made life miserable for Eli Manning in a 27-6 victory over New York.\"",
         "1"
        ],
        [
         "15",
         "\"Some Retailers Offering Online Rebates\",\"The rebate check is no longer a reward reserved for penny-pinchers with an abundance of paperwork skills and patience. Paperless, online rebates are finally gaining momentum in retail, an industry that has long offered customers electronic options for virtually every other type of transaction, from simple purchases to coupons.\"",
         "3"
        ],
        [
         "16",
         "\"Something #39;s a little fishy about PETA #39;s priorities\",\"News Item: NASA #39;s Cassini-Huygens spacecraft to broadcast French rock  #39;n #39; roll as it approaches Saturn #39;s moon Titan.\"",
         "3"
        ],
        [
         "17",
         "\"Whistling Straits Proves It's Major League\",\"Whistling Straits has received magnificent reviews during the P.G.A. Championship, which is currently in a three-man playoff between Justin Leonard, Vijay Singh and Chris DiMarco.\"",
         "1"
        ],
        [
         "18",
         "\"Suicide Bomber Targets Baghdad Police\",\"BAGHDAD, Iraq - A suicide attacker detonated a car bomb by police on a Baghdad bridge, and U.S. troops foiled a second suicide vehicle bombing in attacks Friday that killed at least five people and wounding at least 21...\"",
         "0"
        ],
        [
         "19",
         "\"Dinosaurs May Have Been Doting Parents -Report (Reuters)\",\"Reuters - Dinosaurs may not all have been the\\terrifying creatures portrayed in blockbuster films but could\\have had a more caring, loving nature.\"",
         "3"
        ],
        [
         "20",
         "\"Study: Supercomputer clusters shortchange security\",\"Group says popular technique threatens U.S. security by sidelining other approaches more suited to decryption and the like.\\&lt;br /&gt;  Photo: IBM's unusual design\\&lt;br /&gt; Photos: The fastest computer on Earth--for now\\\"",
         "3"
        ],
        [
         "21",
         "\"US Airways: Workers should not count on pension\",\"US Airways lawyers told a federal bankruptcy judge here Thursday that the carrier can #39;t afford to maintain its current pension plans.\"",
         "2"
        ],
        [
         "22",
         "\"Fannie Mae Target of Criminal Probe\",\"Federal prosecutors in Washington, DC, have opened an investigation into possible wrongdoing at mortgage giant Fannie Mae, just days after regulators accused the company \"",
         "2"
        ],
        [
         "23",
         "\"U.S. Crude Sets New Record  #36;47 a Barrel (Reuters)\",\"Reuters - U.S. oil futures set a new record  #36;47.01\\a barrel on Wednesday after a new threat against Iraq's oil\\sector by rebel Shi'ite militia.  U.S. crude traded up 26 cents\\to set a new high in the 21-year history of the New York\\Mercantile Exchange contract.\"",
         "2"
        ],
        [
         "24",
         "\"Plenty of Flaws Among the Facts\",\"President Bush and Sen. John F. Kerry disagreed vigorously last night as they tossed out plenty of numbers, and both demonstrated a talent for relying on facts and assertions of questionable origin.\"",
         "0"
        ],
        [
         "25",
         "\"CORRECTED: N.Korea Blast Cause Unclear But Many Theories\",\"(Corrects dates: in paragraphs 4, 9 and 16 ...Sept... instead of ...Aug... and in paragraph 7...Sept. 8 to 9...instead of...Aug. 2 to 3.).\"",
         "0"
        ],
        [
         "26",
         "\"Major ankle op for Thomas\",\"Chicago White Sos slugger Frank Thomas could miss the start of next season after undergoing surgery on his left ankle. The 36-year-old, nicknamed  quot;Big Hurt quot;, had debris removed from the joint, underwent a \"",
         "1"
        ],
        [
         "27",
         "\"Cognos buys Sweden #39;s Frango for US\\$52.2M\",\"Ottawa #39;s Cognos Inc. announced a US\\$52.2-million deal on Tuesday to acquire a Swedish maker of financial reporting software. Cognos said it will acquire Stockholm \"",
         "2"
        ],
        [
         "28",
         "\"France Seeks Return of Reporters in Iraq Amid Headscarf Threat\",\"The French government demanded the release of two journalists kidnapped in Iraq by a group demanding that France rescind a ban on Islamic headscarves in the nation #39;s schools within 48 hours.\"",
         "0"
        ],
        [
         "29",
         "\"ING to Withdraw \\$5 Bln from Janus Funds\",\"NEW YORK (Reuters) - ING US Financial Services said late on Tuesday it will withdraw about \\$5 billion from Janus Capital Group Inc. funds by year-end. \"",
         "2"
        ],
        [
         "30",
         "\"NASA Has Hope for Genesis Samples\",\"Scientists sifting through the wreckage from Wednesday's space capsule crash say some of the experiments can be salvaged, but it won't be easy. By Amit Asaravala.\"",
         "3"
        ],
        [
         "31",
         "\"Renault to invest \\$573 million in South Korea, chairman says\",\"SEOUL - French carmaker Renault plans to invest 600 billion won (\\$573.1 million) in South Korea over the next three years, its chairman said on Tuesday.\"",
         "2"
        ],
        [
         "32",
         "\"North Carolina Cruises\",\"Playing their fifth game in eight days, the Tar Heels get 23 points from Jawad Williams to beat Southern California, 97-65.\"",
         "1"
        ],
        [
         "33",
         "\"Canadians in Southeast Asia at risk from terrorist groups, report cautions (Canadian Press)\",\"Canadian Press - OTTAWA (CP) - Islamic extremists with links to Osama bin Laden's al-Qaida network pose a threat to Canadians living in Southeast Asia, warns a newly obtained intelligence report.\"",
         "0"
        ],
        [
         "34",
         "\"Mars Express Sees Chaos in the Canyon\",\"The adage in space science is that one person's noise is another's signal. When the sun temporarily blocked Earth-Mars links, the orbital and surface science went into a deep sleep to protect from noise becoming a errant signal...\"",
         "3"
        ],
        [
         "35",
         "\"Egyptians Spared No Expense on Animal Mummies (Reuters)\",\"Reuters - Ancient Egyptians revered cats and other\\animals and took as much care in preparing them for their\\passage to the next life as they did with humans, scientists\\said on Wednesday.\"",
         "3"
        ],
        [
         "36",
         "\"Germany Softens Stance on Sending Troops to Iraq (Reuters)\",\"Reuters - Germany said Wednesday it could not rule\\out sending troops to Iraq, dropping its firm refusal to\\consider any deployment to the country whose invasion last year\\it staunchly opposed.\"",
         "0"
        ],
        [
         "37",
         "\"Former NatWest bankers fear  #39;unfair trial #39; if extradited to US\",\"By James Daley in London and Katherine Griffiths in New York. Three former NatWest bankers who are fighting extradition to the US over their alleged involvement in a 4m fraud linked to the collapse of Enron \"",
         "2"
        ],
        [
         "38",
         "\"Three British Muslims join Zarqawi terrorist group in Iraq\",\"The revelation by a resistance leader that three British Muslims have joined the terrorist group holding the Liverpool engineer Kenneth Bigley hostage in Iraq has not only shocked most people in Britain but could cause further fracture in the already \"",
         "0"
        ],
        [
         "39",
         "\"Astros live wild life\",\"HOUSTON -- Phil Garner savored the taste of champagne, the smell of his cigar and the wild celebration going on in the Houston Astros' clubhouse.\"",
         "1"
        ],
        [
         "40",
         "\"Does Life Exist in Antarctic Lake Buried Under Miles of Ice?\",\"Lake Vostok, an Antarctic freshwater lake buried by 2.5 miles (4 kilometers) of ice, may host a diverse community of microbial life-forms, scientists say.\"",
         "3"
        ],
        [
         "41",
         "\"Bush, Kerry Duel Over Health Care Plans (AP)\",\"AP - Sen. John Kerry said Wednesday night that President Bush bears responsibility for a misguided war in Iraq, lost jobs at home and mounting millions without health care. The Republican incumbent tagged his rival in campaign debate as a lifelong liberal bent on raising taxes and government spending.\"",
         "0"
        ],
        [
         "42",
         "\"Securing the gold in Athens\",\"Despite age-old Olympic truce known as the ekecheiria, or \"\"holding of hands,\"\" security experts aren't taking any chances.\\\"",
         "3"
        ],
        [
         "43",
         "\"Microsoft to sell Windows XP sta\",\"Microsoft has announced that it is planning to distribute the low cost stripped down version of Windows XP in Russia, sources say.\"",
         "3"
        ],
        [
         "44",
         "\"Sun Leads Liberty in East Finals Sun 61, Liberty 51\",\"NEW YORK, Oct. 1 -- After building a 16-point lead with a big run, Nykesha Sales didn #39;t want to take a break for halftime. Sales scored 13 of her 15 points in the first half and the Connecticut Sun beat the \"",
         "1"
        ],
        [
         "45",
         "\"Lights out for Maroth, 4-1\",\"Mike Maroth #39;s bid for a .500 season got lost in the lights of Comerica Park on Friday night. Maroth (11-13) was locked in a scoreless pitching duel with Tampa Bay Devil Rays right-hander Rob \"",
         "1"
        ],
        [
         "46",
         "\"Intel Sets Upbeat Tone on Wall Street\",\" LONDON (Reuters) - U.S. shares are set to open higher on  Friday, buoyed by Intel Corp. &lt;A HREF=\"\"http://www.investor.reuters.com/FullQuote.aspx?ticker=INTC.O target=/stocks/quickinfo/fullquote\"\"&gt;INTC.O&lt;/A&gt; after the world's  largest chip maker raised its quarterly revenue target due to  strong demand, but all eyes will be on jobs data before the  opening.\"",
         "2"
        ],
        [
         "47",
         "\"How Germs Suck Iron to Cause Infections (AP)\",\"AP - Could that ancient practice of bleeding patients really have done some good? A scientist says new research on how germs thrive in the body suggests it just may have  #151; for some people.\"",
         "3"
        ],
        [
         "48",
         "\"Halifax forecasts 2 house price fall\",\"House prices will decline 2 per cent over the next year as the market experiences a  quot;measured slowdown quot;, the Halifax said yesterday.\"",
         "2"
        ],
        [
         "49",
         "\"Humana to Acquire CarePlus Health Plans\",\"Health-care insurer Humana Inc. on Monday said it agreed to acquire CarePlus Health Plans of Florida for about \\$408 million in a transaction expected to give a solid boost to 2005 earnings.\"",
         "2"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Irish Claim 2nd Title\",\"Notre Dame goalkeeper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Court rules for BC in flap over exit fee\",\"Bo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Scientific Method Man\",\"Gordon Rugg cracked t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Money From Salvadoran Immigrants Aids Farming...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"U.S. Pounds Falluja Diehards, Violence in Nor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\"Fannie Mae in Deal to Up Capital\",\" WASHINGTO...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\"IBM, AMD develop new use of strained silicon\"...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\"Schumacher takes second best in opening sessi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\"The cream of the crop\",\"Their beacons of hope...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\"NL: Tempers flare in Cubs #39; win\",\"Aramis R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0   \"Irish Claim 2nd Title\",\"Notre Dame goalkeeper...      1\n",
       "1   \"Court rules for BC in flap over exit fee\",\"Bo...      1\n",
       "2   \"Scientific Method Man\",\"Gordon Rugg cracked t...      3\n",
       "3   \"Money From Salvadoran Immigrants Aids Farming...      2\n",
       "4   \"U.S. Pounds Falluja Diehards, Violence in Nor...      0\n",
       "..                                                ...    ...\n",
       "95  \"Fannie Mae in Deal to Up Capital\",\" WASHINGTO...      2\n",
       "96  \"IBM, AMD develop new use of strained silicon\"...      3\n",
       "97  \"Schumacher takes second best in opening sessi...      1\n",
       "98  \"The cream of the crop\",\"Their beacons of hope...      1\n",
       "99  \"NL: Tempers flare in Cubs #39; win\",\"Aramis R...      1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Configurar Modelos LLM\n",
    "\n",
    "### Op√ß√£o A: Usar apenas par√¢metros padr√£o (temp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:32\u001b[0m | \u001b[1mCache LangChain ativado: ..\\..\\data\\.cache\\hf\\langchain_cache.db\u001b[0m\n",
      "\u001b[32m17:11:32\u001b[0m | \u001b[1mLLMAnnotator inicializado\u001b[0m\n",
      "\u001b[32m17:11:32\u001b[0m | \u001b[1mModelos: 5 | Categorias: 4\u001b[0m\n",
      "\u001b[32m17:11:32\u001b[0m | \u001b[32m\u001b[1m‚úì Annotator inicializado com 5 modelos\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.llm_annotation_system.annotation.llm_annotator import LLMAnnotator\n",
    "from src.experiments.base_experiment import DEFAULT_MODELS\n",
    "\n",
    "# Inicializar SEM alternative params\n",
    "annotator = LLMAnnotator(\n",
    "    models=DEFAULT_MODELS,\n",
    "    categories=categories,\n",
    "    api_keys=None,\n",
    "    use_langchain_cache=True,\n",
    "    use_alternative_params=False  # Apenas temp=0\n",
    ")\n",
    "\n",
    "logger.success(f\"‚úì Annotator inicializado com {len(annotator.models)} modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Op√ß√£o B: Usar alternative params (temp=0, 0.3, 0.5)\n",
    "\n",
    "**Aten√ß√£o**: Isso cria 9 modelos (3 base + 6 varia√ß√µes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente para usar alternative params:\n",
    "\n",
    "# annotator = LLMAnnotator(\n",
    "#     models=models,\n",
    "#     categories=categories,\n",
    "#     api_keys=None,\n",
    "#     use_langchain_cache=True,\n",
    "#     use_alternative_params=True  # Expande para 9 modelos\n",
    "# )\n",
    "\n",
    "# logger.success(f\"‚úì Annotator com alternative params: {len(annotator.models)} modelos\")\n",
    "# logger.info(f\"  Modelos expandidos: {annotator.models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Executar Anota√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testar anota√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:12:30\u001b[0m | \u001b[33m\u001b[1m  Modelo: llama3-8b\u001b[0m\n",
      "\u001b[32m17:12:30\u001b[0m | \u001b[33m\u001b[1m  Texto: 191\u001b[0m\n",
      "\u001b[32m17:12:30\u001b[0m | \u001b[33m\u001b[1m  Repeti√ß√µes: 1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='You are an expert data annotator with extensive experience in text classification tasks.\\n\\nYour task is to classify the following text into one of the predefined categories with high precision.\\n\\n**Instructions:**\\n1. Read the text carefully and understand its context\\n2. Consider the nuances and implicit meanings\\n3. Select the most appropriate category based on the content\\n4. Be consistent with your classification criteria\\n5. If the text is ambiguous, choose the most likely category based on dominant features\\n\\n**Available Categories:**\\n- 0: 0\\n- 1: 1\\n- 2: 2\\n- 3: 3\\n\\n**Text to classify:**\\n{text}\\n\\n**Important Guidelines:**\\n- Provide ONLY the category name as your response\\n- Do not include explanations unless specifically requested\\n- Be objective and avoid bias\\n- Consider edge cases carefully\\n- Maintain consistency across similar texts\\n\\n**Your classification (category name only):**'))]) middle=[ChatOllama(model='llama3:8b', num_predict=100, temperature=0.0)] last=StrOutputParser()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:12:35\u001b[0m | \u001b[31m\u001b[1mErro em llama3-8b rep 1: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000023044E26DD0>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:12:35\u001b[0m | \u001b[32m\u001b[1m‚úì Anota√ß√£o completa\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ERROR']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Par√¢metros\n",
    "num_repetitions = 1\n",
    "text = texts[0]\n",
    "model = \"llama3-8b\"\n",
    "\n",
    "# Estimativa\n",
    "total_annotation = len(text) * num_repetitions\n",
    "logger.warning(f\"  Modelo: {model}\")\n",
    "logger.warning(f\"  Texto: {len(text)}\")\n",
    "logger.warning(f\"  Repeti√ß√µes: {num_repetitions}\")\n",
    "\n",
    "# Anotar\n",
    "annotations = annotator.annotate_single(\n",
    "    text=text,\n",
    "    model=model,\n",
    "    num_repetitions=num_repetitions\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Anota√ß√£o completa\")\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotando dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:36\u001b[0m | \u001b[1mTotal de anota√ß√µes: 1500\u001b[0m\n",
      "\u001b[32m17:11:36\u001b[0m | \u001b[33m\u001b[1m  Modelos: 5\u001b[0m\n",
      "\u001b[32m17:11:36\u001b[0m | \u001b[33m\u001b[1m  Textos: 100\u001b[0m\n",
      "\u001b[32m17:11:36\u001b[0m | \u001b[33m\u001b[1m  Repeti√ß√µes: 3\u001b[0m\n",
      "\u001b[32m17:11:36\u001b[0m | \u001b[1mIniciando anota√ß√£o\u001b[0m\n",
      "\u001b[32m17:11:36\u001b[0m | \u001b[1mTextos: 100 | Modelos: 5 | Repeti√ß√µes: 3\u001b[0m\n",
      "\u001b[32m17:11:36\u001b[0m | \u001b[1mTotal de anota√ß√µes: 1500\u001b[0m\n",
      "Anotando:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='You are an expert data annotator with extensive experience in text classification tasks.\\n\\nYour task is to classify the following text into one of the predefined categories with high precision.\\n\\n**Instructions:**\\n1. Read the text carefully and understand its context\\n2. Consider the nuances and implicit meanings\\n3. Select the most appropriate category based on the content\\n4. Be consistent with your classification criteria\\n5. If the text is ambiguous, choose the most likely category based on dominant features\\n\\n**Available Categories:**\\n- 0: 0\\n- 1: 1\\n- 2: 2\\n- 3: 3\\n\\n**Text to classify:**\\n{text}\\n\\n**Important Guidelines:**\\n- Provide ONLY the category name as your response\\n- Do not include explanations unless specifically requested\\n- Be objective and avoid bias\\n- Consider edge cases carefully\\n- Maintain consistency across similar texts\\n\\n**Your classification (category name only):**'))]) middle=[ChatOllama(model='deepseek-r1:8b', num_predict=100, temperature=0.2)] last=StrOutputParser()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:40\u001b[0m | \u001b[31m\u001b[1mErro em deepseek-r1-8b rep 1: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421EFE90>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:11:44\u001b[0m | \u001b[31m\u001b[1mErro em deepseek-r1-8b rep 2: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421F5490>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:11:48\u001b[0m | \u001b[31m\u001b[1mErro em deepseek-r1-8b rep 3: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421F4390>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='You are an expert data annotator with extensive experience in text classification tasks.\\n\\nYour task is to classify the following text into one of the predefined categories with high precision.\\n\\n**Instructions:**\\n1. Read the text carefully and understand its context\\n2. Consider the nuances and implicit meanings\\n3. Select the most appropriate category based on the content\\n4. Be consistent with your classification criteria\\n5. If the text is ambiguous, choose the most likely category based on dominant features\\n\\n**Available Categories:**\\n- 0: 0\\n- 1: 1\\n- 2: 2\\n- 3: 3\\n\\n**Text to classify:**\\n{text}\\n\\n**Important Guidelines:**\\n- Provide ONLY the category name as your response\\n- Do not include explanations unless specifically requested\\n- Be objective and avoid bias\\n- Consider edge cases carefully\\n- Maintain consistency across similar texts\\n\\n**Your classification (category name only):**'))]) middle=[ChatOllama(model='qwen2.5:7b', num_predict=100, temperature=0.2)] last=StrOutputParser()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:11:52\u001b[0m | \u001b[31m\u001b[1mErro em qwen2.5-7b rep 1: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421FEF50>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:11:56\u001b[0m | \u001b[31m\u001b[1mErro em qwen2.5-7b rep 2: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421FFC90>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:12:00\u001b[0m | \u001b[31m\u001b[1mErro em qwen2.5-7b rep 3: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421F5510>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='You are an expert data annotator with extensive experience in text classification tasks.\\n\\nYour task is to classify the following text into one of the predefined categories with high precision.\\n\\n**Instructions:**\\n1. Read the text carefully and understand its context\\n2. Consider the nuances and implicit meanings\\n3. Select the most appropriate category based on the content\\n4. Be consistent with your classification criteria\\n5. If the text is ambiguous, choose the most likely category based on dominant features\\n\\n**Available Categories:**\\n- 0: 0\\n- 1: 1\\n- 2: 2\\n- 3: 3\\n\\n**Text to classify:**\\n{text}\\n\\n**Important Guidelines:**\\n- Provide ONLY the category name as your response\\n- Do not include explanations unless specifically requested\\n- Be objective and avoid bias\\n- Consider edge cases carefully\\n- Maintain consistency across similar texts\\n\\n**Your classification (category name only):**'))]) middle=[ChatOllama(model='gemma2:9b', num_predict=100, temperature=0.2)] last=StrOutputParser()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m17:12:04\u001b[0m | \u001b[31m\u001b[1mErro em gemma2-9b rep 1: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421EF250>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:12:08\u001b[0m | \u001b[31m\u001b[1mErro em gemma2-9b rep 2: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002304220CA50>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n",
      "\u001b[32m17:12:12\u001b[0m | \u001b[31m\u001b[1mErro em gemma2-9b rep 3: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/chat (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000230421F5650>: Failed to establish a new connection: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente'))\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['text'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='You are an expert data annotator with extensive experience in text classification tasks.\\n\\nYour task is to classify the following text into one of the predefined categories with high precision.\\n\\n**Instructions:**\\n1. Read the text carefully and understand its context\\n2. Consider the nuances and implicit meanings\\n3. Select the most appropriate category based on the content\\n4. Be consistent with your classification criteria\\n5. If the text is ambiguous, choose the most likely category based on dominant features\\n\\n**Available Categories:**\\n- 0: 0\\n- 1: 1\\n- 2: 2\\n- 3: 3\\n\\n**Text to classify:**\\n{text}\\n\\n**Important Guidelines:**\\n- Provide ONLY the category name as your response\\n- Do not include explanations unless specifically requested\\n- Be objective and avoid bias\\n- Consider edge cases carefully\\n- Maintain consistency across similar texts\\n\\n**Your classification (category name only):**'))]) middle=[ChatOllama(model='mistral:7b', num_predict=100, temperature=0.0)] last=StrOutputParser()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anotando:   0%|          | 0/100 [00:40<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m sock.connect(sa)\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [WinError 10061] Nenhuma conex√£o p√¥de ser feita porque a m√°quina de destino as recusou ativamente",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Repeti√ß√µes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_repetitions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Anotar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df_annotations = \u001b[43mannotator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m logger.success(\u001b[33m\"\u001b[39m\u001b[33m‚úì Anota√ß√µes completas\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m display(df_annotations.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\llm_annotator.py:212\u001b[39m, in \u001b[36mLLMAnnotator.annotate_dataset\u001b[39m\u001b[34m(self, texts, num_repetitions, prompt_template, examples, save_intermediate)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Anotar com cada modelo\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.models:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     annotations = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mannotate_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# Salvar repeti√ß√µes\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rep_idx, annotation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(annotations):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\llm_annotator.py:162\u001b[39m, in \u001b[36mLLMAnnotator.annotate_single\u001b[39m\u001b[34m(self, text, model, num_repetitions, prompt_template, examples, use_cache)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mannotate_single\u001b[39m(\n\u001b[32m    140\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    141\u001b[39m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     use_cache: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    147\u001b[39m ) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[33;03m    Anota um texto √∫nico\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m \u001b[33;03m        Lista de classifica√ß√µes\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mannotation_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\annotation_engine.py:88\u001b[39m, in \u001b[36mAnnotationEngine.annotate_single\u001b[39m\u001b[34m(self, text, model, llm, num_repetitions, prompt_template, examples, use_cache)\u001b[39m\n\u001b[32m     86\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: cache hit\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mself\u001b[39m.cache.set(cache_key, response)\n\u001b[32m     90\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: cache miss\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\annotation_engine.py:167\u001b[39m, in \u001b[36mAnnotationEngine._invoke_chain\u001b[39m\u001b[34m(self, chain, text)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_invoke_chain\u001b[39m(\u001b[38;5;28mself\u001b[39m, chain: \u001b[38;5;28many\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    157\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m    Invoca chain e retorna resposta\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m \u001b[33;03m        Resposta da LLM\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2499\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m   2497\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2498\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps):\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2500\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2501\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[32m   2502\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2503\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2504\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:158\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    149\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m     **kwargs: Any,\n\u001b[32m    154\u001b[39m ) -> BaseMessage:\n\u001b[32m    155\u001b[39m     config = ensure_config(config)\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    157\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    168\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:560\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    553\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    554\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m     **kwargs: Any,\n\u001b[32m    558\u001b[39m ) -> LLMResult:\n\u001b[32m    559\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:421\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    420\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    422\u001b[39m flattened_outputs = [\n\u001b[32m    423\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    425\u001b[39m ]\n\u001b[32m    426\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:411\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    410\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m         )\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:632\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    636\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:259\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    237\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     **kwargs: Any,\n\u001b[32m    241\u001b[39m ) -> ChatResult:\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    243\u001b[39m \n\u001b[32m    244\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    256\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    267\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    268\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    269\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:190\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m     **kwargs: Any,\n\u001b[32m    188\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    189\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:162\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_chat_stream\u001b[39m(\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    154\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    155\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    156\u001b[39m     **kwargs: Any,\n\u001b[32m    157\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    158\u001b[39m     payload = {\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    160\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    161\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\llms\\ollama.py:231\u001b[39m, in \u001b[36m_OllamaCommon._create_stream\u001b[39m\u001b[34m(self, api_url, payload, stop, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    225\u001b[39m     request_payload = {\n\u001b[32m    226\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    227\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m: payload.get(\u001b[33m\"\u001b[39m\u001b[33mimages\u001b[39m\u001b[33m\"\u001b[39m, []),\n\u001b[32m    228\u001b[39m         **params,\n\u001b[32m    229\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m response.encoding = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\connection.py:494\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers.items():\n\u001b[32m    493\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\http\\client.py:1298\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\http\\client.py:1058\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1056\u001b[39m msg = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._buffer)\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1061\u001b[39m \n\u001b[32m   1062\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1064\u001b[39m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[32m   1065\u001b[39m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[32m   1066\u001b[39m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\http\\client.py:996\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    998\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\connection.py:325\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    327\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mself\u001b[39m._has_connected_to_proxy = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:81\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     79\u001b[39m         err = _\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m             \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\socket.py:499\u001b[39m, in \u001b[36msocket.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_real_close\u001b[39m(\u001b[38;5;28mself\u001b[39m, _ss=_socket.socket):\n\u001b[32m    496\u001b[39m     \u001b[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001b[39;00m\n\u001b[32m    497\u001b[39m     _ss.close(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    500\u001b[39m     \u001b[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001b[39;00m\n\u001b[32m    501\u001b[39m     \u001b[38;5;28mself\u001b[39m._closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._io_refs <= \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Par√¢metros\n",
    "num_repetitions = 3\n",
    "\n",
    "# Estimativa\n",
    "total_annotations = len(texts) * len(annotator.models) * num_repetitions\n",
    "logger.info(f\"Total de anota√ß√µes: {total_annotations}\")\n",
    "logger.warning(f\"  Modelos: {len(annotator.models)}\")\n",
    "logger.warning(f\"  Textos: {len(texts)}\")\n",
    "logger.warning(f\"  Repeti√ß√µes: {num_repetitions}\")\n",
    "\n",
    "# Anotar\n",
    "df_annotations = annotator.annotate_dataset(\n",
    "    texts=texts,\n",
    "    num_repetitions=num_repetitions\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Anota√ß√µes completas\")\n",
    "display(df_annotations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Calcular Consenso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular consenso\n",
    "df_with_consensus = annotator.calculate_consensus(df_annotations)\n",
    "\n",
    "# Estat√≠sticas\n",
    "logger.info(\"\\nüìä Estat√≠sticas de Consenso:\")\n",
    "logger.info(f\"  M√©dia: {df_with_consensus['consensus_score'].mean():.2%}\")\n",
    "logger.info(f\"  Mediana: {df_with_consensus['consensus_score'].median():.2%}\")\n",
    "logger.info(f\"  Desvio padr√£o: {df_with_consensus['consensus_score'].std():.2%}\")\n",
    "\n",
    "# Distribui√ß√£o por n√≠vel\n",
    "levels = df_with_consensus['consensus_level'].value_counts()\n",
    "logger.info(\"\\nDistribui√ß√£o por n√≠vel:\")\n",
    "for level, count in levels.items():\n",
    "    logger.info(f\"  {level}: {count} ({count/len(df_with_consensus):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histograma\n",
    "axes[0].hist(df_with_consensus['consensus_score'], bins=20, edgecolor='black')\n",
    "axes[0].set_xlabel('Consensus Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribui√ß√£o de Scores de Consenso')\n",
    "\n",
    "# Barras por n√≠vel\n",
    "levels.plot(kind='bar', ax=axes[1], color=['green', 'orange', 'red'])\n",
    "axes[1].set_xlabel('N√≠vel de Consenso')\n",
    "axes[1].set_ylabel('Contagem')\n",
    "axes[1].set_title('Casos por N√≠vel de Consenso')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ An√°lise de Alternative Params\n",
    "\n",
    "**Nota**: Esta se√ß√£o s√≥ funciona se `use_alternative_params=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se alternative params foi usado\n",
    "if annotator.use_alternative_params:\n",
    "    logger.info(\"üìä Analisando impacto dos alternative params...\")\n",
    "    \n",
    "    # Agrupar por modelo base\n",
    "    for base_model in models:\n",
    "        # Encontrar varia√ß√µes deste modelo\n",
    "        variations = [m for m in annotator.models if m.startswith(base_model)]\n",
    "        \n",
    "        logger.info(f\"\\n{base_model}:\")\n",
    "        \n",
    "        for var in variations:\n",
    "            if f'{var}_consensus_score' in df_with_consensus.columns:\n",
    "                score = df_with_consensus[f'{var}_consensus_score'].mean()\n",
    "                logger.info(f\"  {var}: {score:.2%} consenso interno\")\n",
    "    \n",
    "    # Comparar temperaturas\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    consensus_cols = [col for col in df_with_consensus.columns \n",
    "                     if '_consensus_score' in col and '_alt' in col or \n",
    "                     (col.replace('_consensus_score', '') in models)]\n",
    "    \n",
    "    if consensus_cols:\n",
    "        means = [df_with_consensus[col].mean() for col in consensus_cols]\n",
    "        labels = [col.replace('_consensus_score', '') for col in consensus_cols]\n",
    "        \n",
    "        ax.bar(labels, means)\n",
    "        ax.set_ylabel('Consenso Interno M√©dio')\n",
    "        ax.set_title('Consenso por Varia√ß√£o de Par√¢metros')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    logger.warning(\"Alternative params n√£o foi usado. Para an√°lise detalhada, reinicialize com use_alternative_params=True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ An√°lise Detalhada de Consenso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consensus_analyzer_refactored import ConsensusAnalyzer\n",
    "\n",
    "# Inicializar analyzer\n",
    "analyzer = ConsensusAnalyzer(categories)\n",
    "\n",
    "# Colunas de consenso\n",
    "consensus_cols = [col for col in df_with_consensus.columns if '_consensus' in col and '_score' not in col]\n",
    "\n",
    "logger.info(f\"Analisando {len(consensus_cols)} anotadores\")\n",
    "\n",
    "# Gerar relat√≥rio\n",
    "report = analyzer.generate_consensus_report(\n",
    "    df=df_with_consensus,\n",
    "    annotator_cols=consensus_cols,\n",
    "    output_dir=\"./results\"\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Relat√≥rio gerado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©tricas\n",
    "logger.info(\"\\nüìä M√©tricas de Concord√¢ncia:\")\n",
    "logger.info(f\"  Fleiss' Kappa: {report['fleiss_kappa']:.3f} ({report['fleiss_interpretation']})\")\n",
    "\n",
    "# Interpreta√ß√£o\n",
    "kappa = report['fleiss_kappa']\n",
    "if kappa > 0.8:\n",
    "    logger.success(\"Concord√¢ncia excelente!\")\n",
    "elif kappa > 0.6:\n",
    "    logger.info(\"Concord√¢ncia boa\")\n",
    "elif kappa > 0.4:\n",
    "    logger.warning(\"Concord√¢ncia moderada\")\n",
    "else:\n",
    "    logger.warning(\"Concord√¢ncia fraca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de concord√¢ncia\n",
    "agreement_df = report['pairwise_agreement']\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(agreement_df, annot=True, fmt='.2f', cmap='YlGnBu', cbar_kws={'label': 'Agreement'})\n",
    "plt.title('Matriz de Concord√¢ncia Par a Par')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos problem√°ticos\n",
    "problematic = report.get('problematic_cases')\n",
    "if problematic is not None and len(problematic) > 0:\n",
    "    logger.warning(f\"\\n‚ö†Ô∏è  {len(problematic)} casos problem√°ticos identificados\")\n",
    "    display(problematic.head())\n",
    "else:\n",
    "    logger.success(\"\\n‚úì Nenhum caso problem√°tico identificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Valida√ß√£o com Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ground_truth:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    \n",
    "    # Adicionar ground truth\n",
    "    df_with_consensus['ground_truth'] = ground_truth\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(\n",
    "        df_with_consensus['ground_truth'],\n",
    "        df_with_consensus['most_common_annotation']\n",
    "    )\n",
    "    \n",
    "    logger.success(f\"\\nüéØ Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    # Classification report\n",
    "    logger.info(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        df_with_consensus['ground_truth'],\n",
    "        df_with_consensus['most_common_annotation']\n",
    "    ))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        df_with_consensus['ground_truth'],\n",
    "        df_with_consensus['most_common_annotation']\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix vs Ground Truth')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./results/confusion_vs_ground_truth.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    logger.info(\"\\n‚ö†Ô∏è  Ground truth n√£o dispon√≠vel - pulando valida√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Criar diret√≥rio\n",
    "results_dir = Path('./results/final')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salvar CSVs\n",
    "df_with_consensus.to_csv(results_dir / 'dataset_anotado_completo.csv', index=False)\n",
    "logger.info(f\"‚úì Salvos: {len(df_with_consensus)} registros\")\n",
    "\n",
    "# Alta confian√ßa\n",
    "high_conf = df_with_consensus[df_with_consensus['consensus_score'] >= 0.8]\n",
    "high_conf.to_csv(results_dir / 'alta_confianca.csv', index=False)\n",
    "logger.info(f\"‚úì Alta confian√ßa: {len(high_conf)} registros\")\n",
    "\n",
    "# Necessita revis√£o\n",
    "low_conf = df_with_consensus[df_with_consensus['consensus_score'] < 0.8]\n",
    "low_conf.to_csv(results_dir / 'necessita_revisao.csv', index=False)\n",
    "logger.info(f\"‚úì Necessita revis√£o: {len(low_conf)} registros\")\n",
    "\n",
    "# Sum√°rio JSON\n",
    "summary = {\n",
    "    'dataset': {\n",
    "        'name': dataset_name,\n",
    "        'total_texts': len(texts),\n",
    "        'categories': categories,\n",
    "        'has_ground_truth': ground_truth is not None\n",
    "    },\n",
    "    'config': {\n",
    "        'models': models,\n",
    "        'total_models': len(annotator.models),\n",
    "        'use_alternative_params': annotator.use_alternative_params,\n",
    "        'num_repetitions': num_repetitions,\n",
    "        'total_annotations': len(texts) * len(annotator.models) * num_repetitions\n",
    "    },\n",
    "    'results': {\n",
    "        'consensus_mean': float(df_with_consensus['consensus_score'].mean()),\n",
    "        'consensus_median': float(df_with_consensus['consensus_score'].median()),\n",
    "        'high_consensus': int((df_with_consensus['consensus_level'] == 'high').sum()),\n",
    "        'medium_consensus': int((df_with_consensus['consensus_level'] == 'medium').sum()),\n",
    "        'low_consensus': int((df_with_consensus['consensus_level'] == 'low').sum()),\n",
    "    },\n",
    "    'metrics': {\n",
    "        'fleiss_kappa': float(report['fleiss_kappa']),\n",
    "        'fleiss_interpretation': report['fleiss_interpretation']\n",
    "    }\n",
    "}\n",
    "\n",
    "if ground_truth:\n",
    "    summary['validation'] = {\n",
    "        'accuracy': float(accuracy)\n",
    "    }\n",
    "\n",
    "with open(results_dir / 'sumario_experimento.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "logger.success(\"\\n‚úì Resultados exportados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\"*80)\n",
    "logger.success(\"RESUMO DO EXPERIMENTO\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "logger.info(f\"\\nüìä Dataset: {dataset_name}\")\n",
    "logger.info(f\"  Textos: {len(texts)}\")\n",
    "logger.info(f\"  Categorias: {len(categories)}\")\n",
    "\n",
    "logger.info(f\"\\nü§ñ Configura√ß√£o:\")\n",
    "logger.info(f\"  Modelos base: {len(models)}\")\n",
    "logger.info(f\"  Total modelos: {len(annotator.models)}\")\n",
    "logger.info(f\"  Alternative params: {annotator.use_alternative_params}\")\n",
    "logger.info(f\"  Repeti√ß√µes: {num_repetitions}\")\n",
    "\n",
    "logger.info(f\"\\nüìà Consenso:\")\n",
    "logger.info(f\"  M√©dia: {df_with_consensus['consensus_score'].mean():.2%}\")\n",
    "logger.info(f\"  Fleiss' Kappa: {report['fleiss_kappa']:.3f} ({report['fleiss_interpretation']})\")\n",
    "\n",
    "if ground_truth:\n",
    "    logger.info(f\"\\nüéØ Valida√ß√£o:\")\n",
    "    logger.info(f\"  Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "logger.info(f\"\\nüìÅ Arquivos gerados em: {results_dir}/\")\n",
    "\n",
    "cache_stats = annotator.get_cache_stats()\n",
    "logger.info(f\"\\nüíæ Cache: {cache_stats['total_entries']} entradas\")\n",
    "\n",
    "logger.success(\"\\n‚úÖ An√°lise completa!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-annotation-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
