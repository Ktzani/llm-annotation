{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ An√°lise de Consenso entre LLMs\n",
    "## Notebook Refatorado com Alternative Params\n",
    "\n",
    "Este notebook usa:\n",
    "- Componentes modulares\n",
    "- Logging com loguru\n",
    "- Integra√ß√£o com HuggingFace\n",
    "- **Alternative params** para testar varia√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m‚úì Setup completo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "\n",
    "# Configurar logging\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    format=\"<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>\",\n",
    "    level=\"INFO\"\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Setup completo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Carregar Dataset do HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:06\u001b[0m | \u001b[1mDatasets dispon√≠veis:\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - agnews\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - mpqa\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - webkb\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - ohsumed\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - acm\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - yelp_2013\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - dblp\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - books\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - reut90\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - wos11967\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - twitter\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - trec\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - wos5736\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - sst1\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - pang_movie\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - movie_review\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - vader_movie\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - subj\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - sst2\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - yelp_reviews\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - 20ng\u001b[0m\n",
      "\u001b[32m14:02:06\u001b[0m | \u001b[1m  - medline\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_loader import load_hf_dataset, load_hf_dataset_as_dataframe, list_available_datasets\n",
    "\n",
    "# Listar datasets\n",
    "logger.info(\"Datasets dispon√≠veis:\")\n",
    "for dataset in list_available_datasets():\n",
    "    logger.info(f\"  - {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:06\u001b[0m | \u001b[1mCarregando dataset: agnews\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mSplit 'train': 510400 exemplos\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mCategorias extra√≠das automaticamente: [0, 1, 2, 3]\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mAmostra reduzida para 100 exemplos\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mColuna de texto: text\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mGround truth carregado da coluna 'label'\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mTextos: 100\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mCategorias: [0, 1, 2, 3]\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mGround truth: Sim\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Carregar dataset\n",
    "dataset_name = \"agnews\"  # Ajuste conforme necess√°rio\n",
    "\n",
    "texts, categories, ground_truth = load_hf_dataset(dataset_name)\n",
    "\n",
    "logger.info(f\"Textos: {len(texts)}\")\n",
    "logger.info(f\"Categorias: {categories}\")\n",
    "logger.info(f\"Ground truth: {'Sim' if ground_truth else 'N√£o'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mAmostra dos textos:\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1m1. \"Irish Claim 2nd Title\",\"Notre Dame goalkeeper Erika Bohn seals the Irish's second NCAA championship...\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1m   Label: 1\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1m2. \"Court rules for BC in flap over exit fee\",\"Boston College cleared a major legal hurdle in its bid t...\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1m   Label: 1\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1m3. \"Scientific Method Man\",\"Gordon Rugg cracked the 400-year-old mystery of the Voynich manuscript. Nex...\u001b[0m\n",
      "\u001b[32m14:02:12\u001b[0m | \u001b[1m   Label: 3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Visualizar amostra\n",
    "logger.info(\"Amostra dos textos:\")\n",
    "for i, text in enumerate(texts[:3]):\n",
    "    logger.info(f\"{i+1}. {text[:100]}...\")\n",
    "    if ground_truth:\n",
    "        logger.info(f\"   Label: {ground_truth[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:12\u001b[0m | \u001b[1mCarregando dataset: agnews\u001b[0m\n",
      "\u001b[32m14:02:17\u001b[0m | \u001b[1mSplit 'train': 510400 exemplos\u001b[0m\n",
      "\u001b[32m14:02:17\u001b[0m | \u001b[1mCategorias extra√≠das automaticamente: [0, 1, 2, 3]\u001b[0m\n",
      "\u001b[32m14:02:17\u001b[0m | \u001b[1mAmostra reduzida para 100 exemplos\u001b[0m\n",
      "\u001b[32m14:02:17\u001b[0m | \u001b[1mColuna de texto: text\u001b[0m\n",
      "\u001b[32m14:02:17\u001b[0m | \u001b[1mGround truth carregado da coluna 'label'\u001b[0m\n",
      "\u001b[32m14:02:17\u001b[0m | \u001b[1mDataFrame criado com 100 linhas\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df, categories = load_hf_dataset_as_dataframe(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Configurar Modelos LLM\n",
    "\n",
    "### Op√ß√£o A: Usar apenas par√¢metros padr√£o (temp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:18\u001b[0m | \u001b[1mCache carregado: 30 entradas\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[1mCache LangChain ativado: ..\\..\\data\\.cache\\langchain\\langchain_cache.db\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[1mTemplate do prompt preparado\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[1mLLMAnnotator inicializado\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[1mModelos: 5 | Categorias: 4\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[32m\u001b[1m‚úì Annotator inicializado com 5 modelos\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.llm_annotation_system.annotation.llm_annotator import LLMAnnotator\n",
    "from src.experiments.base_experiment import DEFAULT_MODELS, BASE_ANNOTATION_PROMPT\n",
    "\n",
    "# Inicializar SEM alternative params\n",
    "annotator = LLMAnnotator(\n",
    "    dataset_name=dataset_name,\n",
    "    prompt_template=BASE_ANNOTATION_PROMPT,\n",
    "    models=DEFAULT_MODELS,\n",
    "    categories=categories,\n",
    "    api_keys=None,\n",
    "    use_langchain_cache=True,\n",
    "    use_alternative_params=False  # Apenas temp=0\n",
    ")\n",
    "\n",
    "logger.success(f\"‚úì Annotator inicializado com {len(annotator.models)} modelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert data annotator with extensive experience in text classification tasks.\\n\\nYour task is to classify the following text into one of the predefined categories with high precision.\\n\\n**Instructions:**\\n1. Read the text carefully and understand its context\\n2. Consider the nuances and implicit meanings\\n3. Select the most appropriate category based on the content\\n4. Be consistent with your classification criteria\\n5. If the text is ambiguous, choose the most likely category based on dominant features\\n\\n**Available Categories:**\\n- 0: world\\n- 1: sports\\n- 2: business\\n- 3: Sci/Tech\\n\\n**Text to classify:**\\n{text}\\n\\n**Important Guidelines:**\\n- Provide ONLY the category number as your response\\n- Do not include explanations\\n- Be objective and avoid bias\\n- Consider edge cases carefully\\n- Maintain consistency across similar texts\\n\\n**Your classification (category number only):**'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator.annotation_engine.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Op√ß√£o B: Usar alternative params (temp=0, 0.3, 0.5)\n",
    "\n",
    "**Aten√ß√£o**: Isso cria 9 modelos (3 base + 6 varia√ß√µes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente para usar alternative params:\n",
    "\n",
    "# annotator = LLMAnnotator(\n",
    "#     models=models,\n",
    "#     categories=categories,\n",
    "#     api_keys=None,\n",
    "#     use_langchain_cache=True,\n",
    "#     use_alternative_params=True  # Expande para 9 modelos\n",
    "# )\n",
    "\n",
    "# logger.success(f\"‚úì Annotator com alternative params: {len(annotator.models)} modelos\")\n",
    "# logger.info(f\"  Modelos expandidos: {annotator.models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Executar Anota√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testar anota√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label_description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bd3fdf42-e4d6-424e-9702-37531b1f198c",
       "rows": [
        [
         "0",
         "\"Irish Claim 2nd Title\",\"Notre Dame goalkeeper Erika Bohn seals the Irish's second NCAA championship with a save in penalty kicks to lift them to a 4-3 victory over North Carolina on Sunday.\"",
         "1",
         "sports"
        ],
        [
         "1",
         "\"Court rules for BC in flap over exit fee\",\"Boston College cleared a major legal hurdle in its bid to join the Atlantic Coast Conference yesterday when a Massachusetts Superior Court judge issued summary judgment in favor of the school's attempt to depart the Big East next July under the old provisions of the conference's constitution.\"",
         "1",
         "sports"
        ],
        [
         "2",
         "\"Scientific Method Man\",\"Gordon Rugg cracked the 400-year-old mystery of the Voynich manuscript. Next up: everything from Alzheimer's to the origins of the universe. By Joseph D'Agnese from Wired magazine.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "3",
         "\"Money From Salvadoran Immigrants Aids Farming Cooperative Back Home\",\"SAN PEDRO MASAHUAT, El Salvador -- Marta Sonia Ayala hunched over a metal table in a room that resembles a large restaurant kitchen, scooping heaps of a light brown powder into plastic bags. Later, she placed the bags of &lt;em&gt;frijolito&lt;/em&gt; -- beans ground into flour -- in a heat-sealing machine, placed colored labels on them and shipped them to 22 stores throughout the country where they would sell for \\$1.35 a pound.\"",
         "2",
         "business"
        ],
        [
         "4",
         "\"U.S. Pounds Falluja Diehards, Violence in North\",\" FALLUJA, Iraq (Reuters) - U.S. artillery pummelled Falluja  on Wednesday and troops hunted guerrillas still fighting days  after Washington said its offensive had destroyed rebel control  of the Sunni Muslim city west of Baghdad.\"",
         "0",
         "world"
        ],
        [
         "5",
         "\"Roon at the top - hat-trick hero Wayne makes dazzling United debut\",\"WAYNE ROONEY launched himself into the footballing stratosphere with a debut hat-trick at Old Trafford last night. On this evidence, Sir Alex Ferguson would have made a wise investment if he had spent the \"",
         "1",
         "sports"
        ],
        [
         "6",
         "\"Indonesia steps up clamp on militants\",\"JAKARTA: Indonesian police said yesterday they had redoubled efforts to track militants blamed for a suicide car bomb attack on the Australian embassy, and released video recordings of the powerful blast.\"",
         "0",
         "world"
        ],
        [
         "7",
         "\"Friendly Audience for Hamm\",\"aul Hamm was no longer in Athens last night but instead was on the set of  quot;Late Show With David Letterman quot; carrying his three Olympic medals.\"",
         "1",
         "sports"
        ],
        [
         "8",
         "\"Hurricane Jeanne Continues to Ravage Fla.\",\"MELBOURNE, Fla. - Hurricane Jeanne tore a fresh path of destruction and despair as it continued its march up storm-ravaged Florida, where the fourth major hurricane in six weeks shut down much of the state and prompted recovery plans on a scale never before seen in the nation...\"",
         "0",
         "world"
        ],
        [
         "9",
         "\"Fed minutes show dissent over inflation (USATODAY.com)\",\"USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.\"",
         "2",
         "business"
        ],
        [
         "10",
         "\"XM Satellite Radio to Begin Broadcasting on Web\",\"XM Satellite Radio Holdings Inc. (XMSR) will soon begin broadcasting some of its stations to subscribers over the Internet, fresh on the heels of the company's discontinuation of a receiver for PCs that some users used to circumvent the music industry's crackdown on illegal file sharing.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "11",
         "\"BT And Blueprint Jointly Develop Innovative Music Distribution &lt;b&gt;...&lt;/b&gt;\",\"In yet another move in the legitimate digital music market, BT and Blueprint have jointly developed a new service based on Blueprints Open Royalty Gateway (ORG) and Song Centre software that allows copyright holders to take more control of their \"",
         "3",
         "Sci/Tech"
        ],
        [
         "12",
         "\"Yahoo! awards world #39;s best cybercafes\",\"London, September 1: A San Francisco laundromat may be the one of the world #39;s most unusual places to surf the Internet but a sleek club on Moscow #39;s Red Square is definitely the sleekest, according to a Yahoo!\"",
         "3",
         "Sci/Tech"
        ],
        [
         "13",
         "\"Dollar Dips Against Most Major Currencies\",\" NEW YORK (Reuters) - The dollar dipped against most major  currencies on Wednesday after mixed data on U.S. durable goods  orders and weaker-than-expected new home sales did little to  brighten the U.S. economic outlook.\"",
         "2",
         "business"
        ],
        [
         "14",
         "\"Sunday #39;s NFL Capsules\",\"Philadelphia won a fourth consecutive NFC East title as Brian Westbrook scored two touchdowns Sunday and the Eagles #39; defense made life miserable for Eli Manning in a 27-6 victory over New York.\"",
         "1",
         "sports"
        ],
        [
         "15",
         "\"Some Retailers Offering Online Rebates\",\"The rebate check is no longer a reward reserved for penny-pinchers with an abundance of paperwork skills and patience. Paperless, online rebates are finally gaining momentum in retail, an industry that has long offered customers electronic options for virtually every other type of transaction, from simple purchases to coupons.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "16",
         "\"Something #39;s a little fishy about PETA #39;s priorities\",\"News Item: NASA #39;s Cassini-Huygens spacecraft to broadcast French rock  #39;n #39; roll as it approaches Saturn #39;s moon Titan.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "17",
         "\"Whistling Straits Proves It's Major League\",\"Whistling Straits has received magnificent reviews during the P.G.A. Championship, which is currently in a three-man playoff between Justin Leonard, Vijay Singh and Chris DiMarco.\"",
         "1",
         "sports"
        ],
        [
         "18",
         "\"Suicide Bomber Targets Baghdad Police\",\"BAGHDAD, Iraq - A suicide attacker detonated a car bomb by police on a Baghdad bridge, and U.S. troops foiled a second suicide vehicle bombing in attacks Friday that killed at least five people and wounding at least 21...\"",
         "0",
         "world"
        ],
        [
         "19",
         "\"Dinosaurs May Have Been Doting Parents -Report (Reuters)\",\"Reuters - Dinosaurs may not all have been the\\terrifying creatures portrayed in blockbuster films but could\\have had a more caring, loving nature.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "20",
         "\"Study: Supercomputer clusters shortchange security\",\"Group says popular technique threatens U.S. security by sidelining other approaches more suited to decryption and the like.\\&lt;br /&gt;  Photo: IBM's unusual design\\&lt;br /&gt; Photos: The fastest computer on Earth--for now\\\"",
         "3",
         "Sci/Tech"
        ],
        [
         "21",
         "\"US Airways: Workers should not count on pension\",\"US Airways lawyers told a federal bankruptcy judge here Thursday that the carrier can #39;t afford to maintain its current pension plans.\"",
         "2",
         "business"
        ],
        [
         "22",
         "\"Fannie Mae Target of Criminal Probe\",\"Federal prosecutors in Washington, DC, have opened an investigation into possible wrongdoing at mortgage giant Fannie Mae, just days after regulators accused the company \"",
         "2",
         "business"
        ],
        [
         "23",
         "\"U.S. Crude Sets New Record  #36;47 a Barrel (Reuters)\",\"Reuters - U.S. oil futures set a new record  #36;47.01\\a barrel on Wednesday after a new threat against Iraq's oil\\sector by rebel Shi'ite militia.  U.S. crude traded up 26 cents\\to set a new high in the 21-year history of the New York\\Mercantile Exchange contract.\"",
         "2",
         "business"
        ],
        [
         "24",
         "\"Plenty of Flaws Among the Facts\",\"President Bush and Sen. John F. Kerry disagreed vigorously last night as they tossed out plenty of numbers, and both demonstrated a talent for relying on facts and assertions of questionable origin.\"",
         "0",
         "world"
        ],
        [
         "25",
         "\"CORRECTED: N.Korea Blast Cause Unclear But Many Theories\",\"(Corrects dates: in paragraphs 4, 9 and 16 ...Sept... instead of ...Aug... and in paragraph 7...Sept. 8 to 9...instead of...Aug. 2 to 3.).\"",
         "0",
         "world"
        ],
        [
         "26",
         "\"Major ankle op for Thomas\",\"Chicago White Sos slugger Frank Thomas could miss the start of next season after undergoing surgery on his left ankle. The 36-year-old, nicknamed  quot;Big Hurt quot;, had debris removed from the joint, underwent a \"",
         "1",
         "sports"
        ],
        [
         "27",
         "\"Cognos buys Sweden #39;s Frango for US\\$52.2M\",\"Ottawa #39;s Cognos Inc. announced a US\\$52.2-million deal on Tuesday to acquire a Swedish maker of financial reporting software. Cognos said it will acquire Stockholm \"",
         "2",
         "business"
        ],
        [
         "28",
         "\"France Seeks Return of Reporters in Iraq Amid Headscarf Threat\",\"The French government demanded the release of two journalists kidnapped in Iraq by a group demanding that France rescind a ban on Islamic headscarves in the nation #39;s schools within 48 hours.\"",
         "0",
         "world"
        ],
        [
         "29",
         "\"ING to Withdraw \\$5 Bln from Janus Funds\",\"NEW YORK (Reuters) - ING US Financial Services said late on Tuesday it will withdraw about \\$5 billion from Janus Capital Group Inc. funds by year-end. \"",
         "2",
         "business"
        ],
        [
         "30",
         "\"NASA Has Hope for Genesis Samples\",\"Scientists sifting through the wreckage from Wednesday's space capsule crash say some of the experiments can be salvaged, but it won't be easy. By Amit Asaravala.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "31",
         "\"Renault to invest \\$573 million in South Korea, chairman says\",\"SEOUL - French carmaker Renault plans to invest 600 billion won (\\$573.1 million) in South Korea over the next three years, its chairman said on Tuesday.\"",
         "2",
         "business"
        ],
        [
         "32",
         "\"North Carolina Cruises\",\"Playing their fifth game in eight days, the Tar Heels get 23 points from Jawad Williams to beat Southern California, 97-65.\"",
         "1",
         "sports"
        ],
        [
         "33",
         "\"Canadians in Southeast Asia at risk from terrorist groups, report cautions (Canadian Press)\",\"Canadian Press - OTTAWA (CP) - Islamic extremists with links to Osama bin Laden's al-Qaida network pose a threat to Canadians living in Southeast Asia, warns a newly obtained intelligence report.\"",
         "0",
         "world"
        ],
        [
         "34",
         "\"Mars Express Sees Chaos in the Canyon\",\"The adage in space science is that one person's noise is another's signal. When the sun temporarily blocked Earth-Mars links, the orbital and surface science went into a deep sleep to protect from noise becoming a errant signal...\"",
         "3",
         "Sci/Tech"
        ],
        [
         "35",
         "\"Egyptians Spared No Expense on Animal Mummies (Reuters)\",\"Reuters - Ancient Egyptians revered cats and other\\animals and took as much care in preparing them for their\\passage to the next life as they did with humans, scientists\\said on Wednesday.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "36",
         "\"Germany Softens Stance on Sending Troops to Iraq (Reuters)\",\"Reuters - Germany said Wednesday it could not rule\\out sending troops to Iraq, dropping its firm refusal to\\consider any deployment to the country whose invasion last year\\it staunchly opposed.\"",
         "0",
         "world"
        ],
        [
         "37",
         "\"Former NatWest bankers fear  #39;unfair trial #39; if extradited to US\",\"By James Daley in London and Katherine Griffiths in New York. Three former NatWest bankers who are fighting extradition to the US over their alleged involvement in a 4m fraud linked to the collapse of Enron \"",
         "2",
         "business"
        ],
        [
         "38",
         "\"Three British Muslims join Zarqawi terrorist group in Iraq\",\"The revelation by a resistance leader that three British Muslims have joined the terrorist group holding the Liverpool engineer Kenneth Bigley hostage in Iraq has not only shocked most people in Britain but could cause further fracture in the already \"",
         "0",
         "world"
        ],
        [
         "39",
         "\"Astros live wild life\",\"HOUSTON -- Phil Garner savored the taste of champagne, the smell of his cigar and the wild celebration going on in the Houston Astros' clubhouse.\"",
         "1",
         "sports"
        ],
        [
         "40",
         "\"Does Life Exist in Antarctic Lake Buried Under Miles of Ice?\",\"Lake Vostok, an Antarctic freshwater lake buried by 2.5 miles (4 kilometers) of ice, may host a diverse community of microbial life-forms, scientists say.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "41",
         "\"Bush, Kerry Duel Over Health Care Plans (AP)\",\"AP - Sen. John Kerry said Wednesday night that President Bush bears responsibility for a misguided war in Iraq, lost jobs at home and mounting millions without health care. The Republican incumbent tagged his rival in campaign debate as a lifelong liberal bent on raising taxes and government spending.\"",
         "0",
         "world"
        ],
        [
         "42",
         "\"Securing the gold in Athens\",\"Despite age-old Olympic truce known as the ekecheiria, or \"\"holding of hands,\"\" security experts aren't taking any chances.\\\"",
         "3",
         "Sci/Tech"
        ],
        [
         "43",
         "\"Microsoft to sell Windows XP sta\",\"Microsoft has announced that it is planning to distribute the low cost stripped down version of Windows XP in Russia, sources say.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "44",
         "\"Sun Leads Liberty in East Finals Sun 61, Liberty 51\",\"NEW YORK, Oct. 1 -- After building a 16-point lead with a big run, Nykesha Sales didn #39;t want to take a break for halftime. Sales scored 13 of her 15 points in the first half and the Connecticut Sun beat the \"",
         "1",
         "sports"
        ],
        [
         "45",
         "\"Lights out for Maroth, 4-1\",\"Mike Maroth #39;s bid for a .500 season got lost in the lights of Comerica Park on Friday night. Maroth (11-13) was locked in a scoreless pitching duel with Tampa Bay Devil Rays right-hander Rob \"",
         "1",
         "sports"
        ],
        [
         "46",
         "\"Intel Sets Upbeat Tone on Wall Street\",\" LONDON (Reuters) - U.S. shares are set to open higher on  Friday, buoyed by Intel Corp. &lt;A HREF=\"\"http://www.investor.reuters.com/FullQuote.aspx?ticker=INTC.O target=/stocks/quickinfo/fullquote\"\"&gt;INTC.O&lt;/A&gt; after the world's  largest chip maker raised its quarterly revenue target due to  strong demand, but all eyes will be on jobs data before the  opening.\"",
         "2",
         "business"
        ],
        [
         "47",
         "\"How Germs Suck Iron to Cause Infections (AP)\",\"AP - Could that ancient practice of bleeding patients really have done some good? A scientist says new research on how germs thrive in the body suggests it just may have  #151; for some people.\"",
         "3",
         "Sci/Tech"
        ],
        [
         "48",
         "\"Halifax forecasts 2 house price fall\",\"House prices will decline 2 per cent over the next year as the market experiences a  quot;measured slowdown quot;, the Halifax said yesterday.\"",
         "2",
         "business"
        ],
        [
         "49",
         "\"Humana to Acquire CarePlus Health Plans\",\"Health-care insurer Humana Inc. on Monday said it agreed to acquire CarePlus Health Plans of Florida for about \\$408 million in a transaction expected to give a solid boost to 2005 earnings.\"",
         "2",
         "business"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 100
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Irish Claim 2nd Title\",\"Notre Dame goalkeeper...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Court rules for BC in flap over exit fee\",\"Bo...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Scientific Method Man\",\"Gordon Rugg cracked t...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Money From Salvadoran Immigrants Aids Farming...</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"U.S. Pounds Falluja Diehards, Violence in Nor...</td>\n",
       "      <td>0</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\"Fannie Mae in Deal to Up Capital\",\" WASHINGTO...</td>\n",
       "      <td>2</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\"IBM, AMD develop new use of strained silicon\"...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\"Schumacher takes second best in opening sessi...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\"The cream of the crop\",\"Their beacons of hope...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\"NL: Tempers flare in Cubs #39; win\",\"Aramis R...</td>\n",
       "      <td>1</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label label_description\n",
       "0   \"Irish Claim 2nd Title\",\"Notre Dame goalkeeper...      1            sports\n",
       "1   \"Court rules for BC in flap over exit fee\",\"Bo...      1            sports\n",
       "2   \"Scientific Method Man\",\"Gordon Rugg cracked t...      3          Sci/Tech\n",
       "3   \"Money From Salvadoran Immigrants Aids Farming...      2          business\n",
       "4   \"U.S. Pounds Falluja Diehards, Violence in Nor...      0             world\n",
       "..                                                ...    ...               ...\n",
       "95  \"Fannie Mae in Deal to Up Capital\",\" WASHINGTO...      2          business\n",
       "96  \"IBM, AMD develop new use of strained silicon\"...      3          Sci/Tech\n",
       "97  \"Schumacher takes second best in opening sessi...      1            sports\n",
       "98  \"The cream of the crop\",\"Their beacons of hope...      1            sports\n",
       "99  \"NL: Tempers flare in Cubs #39; win\",\"Aramis R...      1            sports\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:18\u001b[0m | \u001b[33m\u001b[1m  Modelo: deepseek-r1-8b\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[33m\u001b[1m  Texto: 191\u001b[0m\n",
      "\u001b[32m14:02:18\u001b[0m | \u001b[33m\u001b[1m  Repeti√ß√µes: 3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n1' response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-11-30T17:02:27.6361282Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 7177027300, 'load_duration': 2300431900, 'prompt_eval_count': 482, 'prompt_eval_duration': 45010800, 'eval_count': 3, 'eval_duration': 40748800} id='run-6ad79fea-6e3f-4cfc-a643-dc73192e7281-0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:28\u001b[0m | \u001b[32m\u001b[1m‚úì Anota√ß√£o completa\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n1' response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-11-30T17:02:27.6361282Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 7177027300, 'load_duration': 2300431900, 'prompt_eval_count': 482, 'prompt_eval_duration': 45010800, 'eval_count': 3, 'eval_duration': 40748800} id='run-6ad79fea-6e3f-4cfc-a643-dc73192e7281-0'\n",
      "content='\\n1' response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-11-30T17:02:27.6361282Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 7177027300, 'load_duration': 2300431900, 'prompt_eval_count': 482, 'prompt_eval_duration': 45010800, 'eval_count': 3, 'eval_duration': 40748800} id='run-6ad79fea-6e3f-4cfc-a643-dc73192e7281-0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Par√¢metros\n",
    "num_repetitions = 3\n",
    "text = texts[0]\n",
    "model = \"qwen3-8b\"\n",
    "\n",
    "# Estimativa\n",
    "total_annotation = len(text) * num_repetitions\n",
    "logger.warning(f\"  Modelo: {model}\")\n",
    "logger.warning(f\"  Texto: {len(text)}\")\n",
    "logger.warning(f\"  Repeti√ß√µes: {num_repetitions}\")\n",
    "\n",
    "# Anotar\n",
    "annotations = annotator.annotate_single(\n",
    "    text=text,\n",
    "    model=model,\n",
    "    num_repetitions=num_repetitions,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Anota√ß√£o completa\")\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotando dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:02:28\u001b[0m | \u001b[1mIniciando anota√ß√£o\u001b[0m\n",
      "\u001b[32m14:02:28\u001b[0m | \u001b[1mTextos: 100 | Modelos: 5 | Repeti√ß√µes: 1\u001b[0m\n",
      "\u001b[32m14:02:28\u001b[0m | \u001b[1mTotal de anota√ß√µes: 500\u001b[0m\n",
      "Anotando:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[32m14:02:28\u001b[0m | \u001b[33m\u001b[1mResposta √© None ou ''\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\n1' response_metadata={'model': 'deepseek-r1:8b', 'created_at': '2025-11-30T17:02:27.6361282Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 7177027300, 'load_duration': 2300431900, 'prompt_eval_count': 482, 'prompt_eval_duration': 45010800, 'eval_count': 3, 'eval_duration': 40748800} id='run-6ad79fea-6e3f-4cfc-a643-dc73192e7281-0'\n",
      "content='' response_metadata={'model': 'qwen3:8b', 'created_at': '2025-11-30T16:18:26.7282287Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'length', 'total_duration': 4311233300, 'load_duration': 2293494600, 'prompt_eval_count': 238, 'prompt_eval_duration': 133626800, 'eval_count': 100, 'eval_duration': 1825898800} id='run-9dab1461-25b0-44fa-8218-e5610d49f165-0'\n",
      "content='1\\n' response_metadata={'model': 'gemma3:4b', 'created_at': '2025-11-30T15:45:13.5630884Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 4616828200, 'load_duration': 4481317900, 'prompt_eval_count': 239, 'prompt_eval_duration': 77240600, 'eval_count': 3, 'eval_duration': 29689700} id='run-6fe57270-a79d-4499-829a-dc5ffc4e1b3a-0'\n",
      "content=' 3' response_metadata={'model': 'mistral:7b', 'created_at': '2025-11-30T15:45:15.8327857Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 125879300, 'load_duration': 15834700, 'prompt_eval_count': 266, 'prompt_eval_duration': 73055400, 'eval_count': 3, 'eval_duration': 34449900} id='run-deea71ab-cfd0-48f4-964a-529706f8d928-0'\n",
      "content='1' response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-11-30T15:44:50.1671285Z', 'message': {'role': 'assistant', 'content': ''}, 'done': True, 'done_reason': 'stop', 'total_duration': 4306987100, 'load_duration': 4148444600, 'prompt_eval_count': 238, 'prompt_eval_duration': 133059400, 'eval_count': 2, 'eval_duration': 22044200} id='run-b54fcf54-d8b2-4a19-8216-d88eda353e01-0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anotando:   1%|          | 1/100 [00:04<08:10,  4.96s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m num_repetitions = \u001b[32m1\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Anotar\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_annotations = \u001b[43mannotator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m logger.success(\u001b[33m\"\u001b[39m\u001b[33m‚úì Anota√ß√µes completas\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m display(df_annotations.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\llm_annotator.py:215\u001b[39m, in \u001b[36mLLMAnnotator.annotate_dataset\u001b[39m\u001b[34m(self, texts, num_repetitions, save_intermediate, use_cache)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# Anotar com cada modelo\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.models:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     annotations = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mannotate_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# Salvar repeti√ß√µes\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rep_idx, annotation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(annotations):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\llm_annotator.py:168\u001b[39m, in \u001b[36mLLMAnnotator.annotate_single\u001b[39m\u001b[34m(self, text, model, num_repetitions, use_cache)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mannotate_single\u001b[39m(\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    149\u001b[39m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    152\u001b[39m     use_cache: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    153\u001b[39m ) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    154\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m    Anota um texto √∫nico\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    166\u001b[39m \u001b[33;03m        Lista de classifica√ß√µes\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mannotation_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mannotate_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\annotation_engine.py:74\u001b[39m, in \u001b[36mAnnotationEngine.annotate_single\u001b[39m\u001b[34m(self, text, model, llm, num_repetitions, use_cache)\u001b[39m\n\u001b[32m     72\u001b[39m         logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: cache miss\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_direct_llm_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# ---------- EXTRAI A CATEGORIA ----------\u001b[39;00m\n\u001b[32m     77\u001b[39m category = \u001b[38;5;28mself\u001b[39m.response_processor.extract_category(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\llm-annotation\\src\\llm_annotation_system\\annotation\\annotation_engine.py:154\u001b[39m, in \u001b[36mAnnotationEngine._direct_llm_call\u001b[39m\u001b[34m(self, llm, text)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdeepseek\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m llm.model.lower():\n\u001b[32m    152\u001b[39m     prompt += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m<think>\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m raw = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mprint\u001b[39m(raw)\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Caso 1: LangChain retorna AIMessage\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:158\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    148\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    149\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m     **kwargs: Any,\n\u001b[32m    154\u001b[39m ) -> BaseMessage:\n\u001b[32m    155\u001b[39m     config = ensure_config(config)\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    157\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    168\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:560\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    553\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    554\u001b[39m     prompts: List[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    557\u001b[39m     **kwargs: Any,\n\u001b[32m    558\u001b[39m ) -> LLMResult:\n\u001b[32m    559\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:421\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    420\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    422\u001b[39m flattened_outputs = [\n\u001b[32m    423\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    425\u001b[39m ]\n\u001b[32m    426\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:411\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    410\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m         )\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    419\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:632\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    636\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:259\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    237\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     **kwargs: Any,\n\u001b[32m    241\u001b[39m ) -> ChatResult:\n\u001b[32m    242\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    243\u001b[39m \n\u001b[32m    244\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    256\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    267\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    268\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    269\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:190\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m     **kwargs: Any,\n\u001b[32m    188\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    189\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\langchain_community\\chat_models\\ollama.py:162\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_chat_stream\u001b[39m(\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    154\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    155\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    156\u001b[39m     **kwargs: Any,\n\u001b[32m    157\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    158\u001b[39m     payload = {\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    160\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    161\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_stream(\n\u001b[32m    163\u001b[39m         payload=payload, stop=stop, api_url=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/chat\u001b[39m\u001b[33m\"\u001b[39m, **kwargs\n\u001b[32m    164\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\models.py:869\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self, chunk_size, decode_unicode, delimiter)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[32m    861\u001b[39m \u001b[33;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[32m    862\u001b[39m \u001b[33;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[32m    863\u001b[39m \n\u001b[32m    864\u001b[39m \u001b[33;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[32m    865\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    867\u001b[39m pending = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\utils.py:562\u001b[39m, in \u001b[36mstream_decode_response_unicode\u001b[39m\u001b[34m(iterator, r)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    561\u001b[39m decoder = codecs.getincrementaldecoder(r.encoding)(errors=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\response.py:1248\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1245\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\urllib3\\response.py:1167\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m line = \u001b[38;5;28mself\u001b[39m._fp.fp.readline()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1168\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    708\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Par√¢metros\n",
    "num_repetitions = 1\n",
    "\n",
    "# Anotar\n",
    "df_annotations = annotator.annotate_dataset(\n",
    "    texts=texts,\n",
    "    num_repetitions=num_repetitions,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Anota√ß√µes completas\")\n",
    "display(df_annotations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Calcular Consenso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular consenso\n",
    "df_with_consensus = annotator.calculate_consensus(df_annotations)\n",
    "\n",
    "# Estat√≠sticas\n",
    "logger.info(\"\\nüìä Estat√≠sticas de Consenso:\")\n",
    "logger.info(f\"  M√©dia: {df_with_consensus['consensus_score'].mean():.2%}\")\n",
    "logger.info(f\"  Mediana: {df_with_consensus['consensus_score'].median():.2%}\")\n",
    "logger.info(f\"  Desvio padr√£o: {df_with_consensus['consensus_score'].std():.2%}\")\n",
    "\n",
    "# Distribui√ß√£o por n√≠vel\n",
    "levels = df_with_consensus['consensus_level'].value_counts()\n",
    "logger.info(\"\\nDistribui√ß√£o por n√≠vel:\")\n",
    "for level, count in levels.items():\n",
    "    logger.info(f\"  {level}: {count} ({count/len(df_with_consensus):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√µes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histograma\n",
    "axes[0].hist(df_with_consensus['consensus_score'], bins=20, edgecolor='black')\n",
    "axes[0].set_xlabel('Consensus Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribui√ß√£o de Scores de Consenso')\n",
    "\n",
    "# Barras por n√≠vel\n",
    "levels.plot(kind='bar', ax=axes[1], color=['green', 'orange', 'red'])\n",
    "axes[1].set_xlabel('N√≠vel de Consenso')\n",
    "axes[1].set_ylabel('Contagem')\n",
    "axes[1].set_title('Casos por N√≠vel de Consenso')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ An√°lise de Alternative Params\n",
    "\n",
    "**Nota**: Esta se√ß√£o s√≥ funciona se `use_alternative_params=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se alternative params foi usado\n",
    "if annotator.use_alternative_params:\n",
    "    logger.info(\"üìä Analisando impacto dos alternative params...\")\n",
    "    \n",
    "    # Agrupar por modelo base\n",
    "    for base_model in models:\n",
    "        # Encontrar varia√ß√µes deste modelo\n",
    "        variations = [m for m in annotator.models if m.startswith(base_model)]\n",
    "        \n",
    "        logger.info(f\"\\n{base_model}:\")\n",
    "        \n",
    "        for var in variations:\n",
    "            if f'{var}_consensus_score' in df_with_consensus.columns:\n",
    "                score = df_with_consensus[f'{var}_consensus_score'].mean()\n",
    "                logger.info(f\"  {var}: {score:.2%} consenso interno\")\n",
    "    \n",
    "    # Comparar temperaturas\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    consensus_cols = [col for col in df_with_consensus.columns \n",
    "                     if '_consensus_score' in col and '_alt' in col or \n",
    "                     (col.replace('_consensus_score', '') in models)]\n",
    "    \n",
    "    if consensus_cols:\n",
    "        means = [df_with_consensus[col].mean() for col in consensus_cols]\n",
    "        labels = [col.replace('_consensus_score', '') for col in consensus_cols]\n",
    "        \n",
    "        ax.bar(labels, means)\n",
    "        ax.set_ylabel('Consenso Interno M√©dio')\n",
    "        ax.set_title('Consenso por Varia√ß√£o de Par√¢metros')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    logger.warning(\"Alternative params n√£o foi usado. Para an√°lise detalhada, reinicialize com use_alternative_params=True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ An√°lise Detalhada de Consenso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm_annotation_system.consensus.consensus_analyzer import ConsensusAnalyzer\n",
    "\n",
    "# Inicializar analyzer\n",
    "analyzer = ConsensusAnalyzer(categories)\n",
    "\n",
    "# Colunas de consenso\n",
    "consensus_cols = [col for col in df_with_consensus.columns if '_consensus' in col and '_score' not in col]\n",
    "\n",
    "logger.info(f\"Analisando {len(consensus_cols)} anotadores\")\n",
    "\n",
    "# Gerar relat√≥rio\n",
    "report = analyzer.generate_consensus_report(\n",
    "    df=df_with_consensus,\n",
    "    annotator_cols=consensus_cols,\n",
    "    output_dir=\"./results\"\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Relat√≥rio gerado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©tricas\n",
    "logger.info(\"\\nüìä M√©tricas de Concord√¢ncia:\")\n",
    "logger.info(f\"  Fleiss' Kappa: {report['fleiss_kappa']:.3f} ({report['fleiss_interpretation']})\")\n",
    "\n",
    "# Interpreta√ß√£o\n",
    "kappa = report['fleiss_kappa']\n",
    "if kappa > 0.8:\n",
    "    logger.success(\"Concord√¢ncia excelente!\")\n",
    "elif kappa > 0.6:\n",
    "    logger.info(\"Concord√¢ncia boa\")\n",
    "elif kappa > 0.4:\n",
    "    logger.warning(\"Concord√¢ncia moderada\")\n",
    "else:\n",
    "    logger.warning(\"Concord√¢ncia fraca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de concord√¢ncia\n",
    "agreement_df = report['pairwise_agreement']\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(agreement_df, annot=True, fmt='.2f', cmap='YlGnBu', cbar_kws={'label': 'Agreement'})\n",
    "plt.title('Matriz de Concord√¢ncia Par a Par')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos problem√°ticos\n",
    "problematic = report.get('problematic_cases')\n",
    "if problematic is not None and len(problematic) > 0:\n",
    "    logger.warning(f\"\\n‚ö†Ô∏è  {len(problematic)} casos problem√°ticos identificados\")\n",
    "    display(problematic.head())\n",
    "else:\n",
    "    logger.success(\"\\n‚úì Nenhum caso problem√°tico identificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Valida√ß√£o com Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ground_truth:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    \n",
    "    # Adicionar ground truth\n",
    "    df_with_consensus['ground_truth'] = ground_truth\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(\n",
    "        df_with_consensus['ground_truth'],\n",
    "        df_with_consensus['most_common_annotation']\n",
    "    )\n",
    "    \n",
    "    logger.success(f\"\\nüéØ Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    # Classification report\n",
    "    logger.info(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        df_with_consensus['ground_truth'],\n",
    "        df_with_consensus['most_common_annotation']\n",
    "    ))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(\n",
    "        df_with_consensus['ground_truth'],\n",
    "        df_with_consensus['most_common_annotation']\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix vs Ground Truth')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./results/confusion_vs_ground_truth.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    logger.info(\"\\n‚ö†Ô∏è  Ground truth n√£o dispon√≠vel - pulando valida√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Criar diret√≥rio\n",
    "results_dir = Path('./results/final')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salvar CSVs\n",
    "df_with_consensus.to_csv(results_dir / 'dataset_anotado_completo.csv', index=False)\n",
    "logger.info(f\"‚úì Salvos: {len(df_with_consensus)} registros\")\n",
    "\n",
    "# Alta confian√ßa\n",
    "high_conf = df_with_consensus[df_with_consensus['consensus_score'] >= 0.8]\n",
    "high_conf.to_csv(results_dir / 'alta_confianca.csv', index=False)\n",
    "logger.info(f\"‚úì Alta confian√ßa: {len(high_conf)} registros\")\n",
    "\n",
    "# Necessita revis√£o\n",
    "low_conf = df_with_consensus[df_with_consensus['consensus_score'] < 0.8]\n",
    "low_conf.to_csv(results_dir / 'necessita_revisao.csv', index=False)\n",
    "logger.info(f\"‚úì Necessita revis√£o: {len(low_conf)} registros\")\n",
    "\n",
    "# Sum√°rio JSON\n",
    "summary = {\n",
    "    'dataset': {\n",
    "        'name': dataset_name,\n",
    "        'total_texts': len(texts),\n",
    "        'categories': categories,\n",
    "        'has_ground_truth': ground_truth is not None\n",
    "    },\n",
    "    'config': {\n",
    "        'models': models,\n",
    "        'total_models': len(annotator.models),\n",
    "        'use_alternative_params': annotator.use_alternative_params,\n",
    "        'num_repetitions': num_repetitions,\n",
    "        'total_annotations': len(texts) * len(annotator.models) * num_repetitions\n",
    "    },\n",
    "    'results': {\n",
    "        'consensus_mean': float(df_with_consensus['consensus_score'].mean()),\n",
    "        'consensus_median': float(df_with_consensus['consensus_score'].median()),\n",
    "        'high_consensus': int((df_with_consensus['consensus_level'] == 'high').sum()),\n",
    "        'medium_consensus': int((df_with_consensus['consensus_level'] == 'medium').sum()),\n",
    "        'low_consensus': int((df_with_consensus['consensus_level'] == 'low').sum()),\n",
    "    },\n",
    "    'metrics': {\n",
    "        'fleiss_kappa': float(report['fleiss_kappa']),\n",
    "        'fleiss_interpretation': report['fleiss_interpretation']\n",
    "    }\n",
    "}\n",
    "\n",
    "if ground_truth:\n",
    "    summary['validation'] = {\n",
    "        'accuracy': float(accuracy)\n",
    "    }\n",
    "\n",
    "with open(results_dir / 'sumario_experimento.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "logger.success(\"\\n‚úì Resultados exportados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Resumo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\"*80)\n",
    "logger.success(\"RESUMO DO EXPERIMENTO\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "logger.info(f\"\\nüìä Dataset: {dataset_name}\")\n",
    "logger.info(f\"  Textos: {len(texts)}\")\n",
    "logger.info(f\"  Categorias: {len(categories)}\")\n",
    "\n",
    "logger.info(f\"\\nü§ñ Configura√ß√£o:\")\n",
    "logger.info(f\"  Modelos base: {len(models)}\")\n",
    "logger.info(f\"  Total modelos: {len(annotator.models)}\")\n",
    "logger.info(f\"  Alternative params: {annotator.use_alternative_params}\")\n",
    "logger.info(f\"  Repeti√ß√µes: {num_repetitions}\")\n",
    "\n",
    "logger.info(f\"\\nüìà Consenso:\")\n",
    "logger.info(f\"  M√©dia: {df_with_consensus['consensus_score'].mean():.2%}\")\n",
    "logger.info(f\"  Fleiss' Kappa: {report['fleiss_kappa']:.3f} ({report['fleiss_interpretation']})\")\n",
    "\n",
    "if ground_truth:\n",
    "    logger.info(f\"\\nüéØ Valida√ß√£o:\")\n",
    "    logger.info(f\"  Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "logger.info(f\"\\nüìÅ Arquivos gerados em: {results_dir}/\")\n",
    "\n",
    "cache_stats = annotator.get_cache_stats()\n",
    "logger.info(f\"\\nüíæ Cache: {cache_stats['total_entries']} entradas\")\n",
    "\n",
    "logger.success(\"\\n‚úÖ An√°lise completa!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-annotation-py3.11 (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
