{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32db9d9",
   "metadata": {},
   "source": [
    "# üõ† An√°lise labels - Dataset Wash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b319c40",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6650b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m18:16:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m‚úì Setup completo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar logging\n",
    "logger.remove()\n",
    "logger.add(\n",
    "    sys.stdout,\n",
    "    format=\"<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>\",\n",
    "    level=\"INFO\"\n",
    ")\n",
    "\n",
    "logger.success(\"‚úì Setup completo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36295201",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Carregar Dataset do HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9f1041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m18:16:40\u001b[0m | \u001b[1mDatasets dispon√≠veis:\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - agnews\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - mpqa\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - webkb\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - ohsumed\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - acm\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - yelp_2013\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - dblp\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - books\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - reut90\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - wos11967\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - twitter\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - trec\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - wos5736\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - sst1\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - pang_movie\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - movie_review\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - vader_movie\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - subj\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - sst2\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - yelp_reviews\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - 20ng\u001b[0m\n",
      "\u001b[32m18:16:40\u001b[0m | \u001b[1m  - medline\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_loader import load_hf_dataset_as_dataframe, list_available_datasets\n",
    "\n",
    "# Listar datasets\n",
    "logger.info(\"Datasets dispon√≠veis:\")\n",
    "for dataset in list_available_datasets():\n",
    "    logger.info(f\"  - {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "300786c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset\n",
    "dataset_name = \"wos5736\"  # Ajuste conforme necess√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd2842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m18:16:40\u001b[0m | \u001b[1mCarregando dataset: wos5736\u001b[0m\n",
      "\u001b[32m18:16:52\u001b[0m | \u001b[1mSplit 'train': 51624 exemplos\u001b[0m\n",
      "\u001b[32m18:16:52\u001b[0m | \u001b[1mCategorias extra√≠das automaticamente: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\u001b[0m\n",
      "\u001b[32m18:16:52\u001b[0m | \u001b[1mAmostra reduzida para 100 exemplos\u001b[0m\n",
      "\u001b[32m18:16:52\u001b[0m | \u001b[1mColuna de texto: text\u001b[0m\n",
      "\u001b[32m18:16:52\u001b[0m | \u001b[1mGround truth carregado da coluna 'label'\u001b[0m\n",
      "\u001b[32m18:16:52\u001b[0m | \u001b[1mDataFrame criado com 100 linhas\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df, categories = load_hf_dataset_as_dataframe(dataset_name)\n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f44619",
   "metadata": {},
   "source": [
    "## 3) Validando labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05767d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel_description\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6140\u001b[39m, in \u001b[36mNDFrame.sample\u001b[39m\u001b[34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[39m\n\u001b[32m   6137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   6138\u001b[39m     weights = sample.preprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[32m-> \u001b[39m\u001b[32m6140\u001b[39m sampled_indices = \u001b[43msample\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6141\u001b[39m result = \u001b[38;5;28mself\u001b[39m.take(sampled_indices, axis=axis)\n\u001b[32m   6143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\Documents\\GitHub\\llm-annotation\\.venv\\Lib\\site-packages\\pandas\\core\\sample.py:152\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(obj_len, size, replace, weights, random_state)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    150\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid weights: weights sum to zero\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m.astype(\n\u001b[32m    153\u001b[39m     np.intp, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    154\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:1001\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "df[df[\"label\"] == 0][[\"text\", \"label\", \"label_description\"]].sample(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
